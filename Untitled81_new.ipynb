{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled81.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepaManjunath/Assignment1/blob/master/Untitled81_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxSCFJH7wZAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su3AbC31SIT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSfIljN2LoqQ",
        "colab_type": "code",
        "outputId": "46b573de-af28-43d0-975c-3892533d16a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -q '/content/gdrive/My Drive/EIP4/hvc_data.zip'\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls '/content/gdrive/My Drive/EIP4/'"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "replace resized/9733.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "\u001b[0m\u001b[01;34mhvc_data\u001b[0m/  hvc_data.zip  \u001b[01;34mSaveModel\u001b[0m/  train.csv  val.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHPH-SGML1v2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "\n",
        "from keras.applications import VGG16\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation , Dropout\n",
        "from keras.layers import AveragePooling2D, Input, Flatten ,GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VqwrRBqMSHQ",
        "colab_type": "code",
        "outputId": "4604ce09-a125-44d2-d3ea-fe4ede6fb87b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "\n",
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>imagequality</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>carryingbag</th>\n",
              "      <th>footwear</th>\n",
              "      <th>emotion</th>\n",
              "      <th>bodypose</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>over-weight</td>\n",
              "      <td>None</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Angry/Serious</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Daily/Office/Work Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>female</td>\n",
              "      <td>Good</td>\n",
              "      <td>35-45</td>\n",
              "      <td>slightly-overweight</td>\n",
              "      <td>None</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/5.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender imagequality    age  ...        emotion        bodypose     image_path\n",
              "0    male      Average  35-45  ...        Neutral  Front-Frontish  resized/1.jpg\n",
              "1  female      Average  35-45  ...  Angry/Serious  Front-Frontish  resized/2.jpg\n",
              "2    male         Good  45-55  ...        Neutral  Front-Frontish  resized/3.jpg\n",
              "3    male         Good  45-55  ...        Neutral  Front-Frontish  resized/4.jpg\n",
              "4  female         Good  35-45  ...        Neutral  Front-Frontish  resized/5.jpg\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM8y1dJzMX3j",
        "colab_type": "code",
        "outputId": "92c5bdc7-a3fe-439e-fbfc-aa332240873f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        }
      },
      "source": [
        "#one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
        "], axis = 1)\n",
        "\n",
        "one_hot_df.head().T"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>image_path</th>\n",
              "      <td>resized/1.jpg</td>\n",
              "      <td>resized/2.jpg</td>\n",
              "      <td>resized/3.jpg</td>\n",
              "      <td>resized/4.jpg</td>\n",
              "      <td>resized/5.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender_female</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender_male</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Average</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Bad</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Good</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_15-25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_25-35</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_35-45</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_45-55</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_55+</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_normal-healthy</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_over-weight</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_slightly-overweight</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_underweight</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_Daily/Office/Work Bag</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_Grocery/Home/Plastic Bag</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_None</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_CantSee</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_Fancy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_Normal</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Angry/Serious</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Happy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Neutral</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Sad</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Back</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Front-Frontish</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Side</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  0  ...              4\n",
              "image_path                            resized/1.jpg  ...  resized/5.jpg\n",
              "gender_female                                     0  ...              1\n",
              "gender_male                                       1  ...              0\n",
              "imagequality_Average                              1  ...              0\n",
              "imagequality_Bad                                  0  ...              0\n",
              "imagequality_Good                                 0  ...              1\n",
              "age_15-25                                         0  ...              0\n",
              "age_25-35                                         0  ...              0\n",
              "age_35-45                                         1  ...              1\n",
              "age_45-55                                         0  ...              0\n",
              "age_55+                                           0  ...              0\n",
              "weight_normal-healthy                             1  ...              0\n",
              "weight_over-weight                                0  ...              0\n",
              "weight_slightly-overweight                        0  ...              1\n",
              "weight_underweight                                0  ...              0\n",
              "carryingbag_Daily/Office/Work Bag                 0  ...              0\n",
              "carryingbag_Grocery/Home/Plastic Bag              1  ...              0\n",
              "carryingbag_None                                  0  ...              1\n",
              "footwear_CantSee                                  0  ...              1\n",
              "footwear_Fancy                                    0  ...              0\n",
              "footwear_Normal                                   1  ...              0\n",
              "emotion_Angry/Serious                             0  ...              0\n",
              "emotion_Happy                                     0  ...              0\n",
              "emotion_Neutral                                   1  ...              1\n",
              "emotion_Sad                                       0  ...              0\n",
              "bodypose_Back                                     0  ...              0\n",
              "bodypose_Front-Frontish                           1  ...              1\n",
              "bodypose_Side                                     0  ...              0\n",
              "\n",
              "[28 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZRh5N-eMi8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
        "    def eraser(input_img):\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "\n",
        "    return eraser"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8W2ZYHVO6ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# Label columns per attribute\n",
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
        "\n",
        "class PersonDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Ground truth data generator\"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self, df, batch_size=32, shuffle=True,augmentation=None):\n",
        "        self.df = df\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_size = batch_size\n",
        "        #self.labels = labels\n",
        "        #self.list_IDs = list_IDs\n",
        "        #self.n_channels = n_channels\n",
        "        #self.n_classes = n_classes\n",
        "        #self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.augmentation=augmentation\n",
        "        \n",
        "        \n",
        "        #self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "            \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"fetch batched images and targets\"\"\"\n",
        "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        items = self.df.iloc[batch_slice]\n",
        "        images = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
        "        if self.augmentation is not None:\n",
        "           images=self.augmentation.flow(images,shuffle=False).next()\n",
        "           \n",
        "        target = {\n",
        "                       \"gender_output\": items[_gender_cols_].values,\n",
        "                       \"image_quality_output\": items[_imagequality_cols_].values,\n",
        "                       \"age_output\": items[_age_cols_].values,\n",
        "                       \"weight_output\": items[_weight_cols_].values,\n",
        "                       \"bag_output\": items[_carryingbag_cols_].values,\n",
        "                       \"pose_output\": items[_bodypose_cols_].values,\n",
        "                       \"footwear_output\": items[_footwear_cols_].values,\n",
        "                       \"emotion_output\": items[_emotion_cols_].values,\n",
        "        }\n",
        "        return images, target\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.shuffle == True:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
        "            \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_6UcCbKPCd6",
        "colab_type": "code",
        "outputId": "1cf30589-275c-4881-9d8a-0c3f3554b710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.15)\n",
        "train_df.shape, val_df.shape\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11537, 28), (2036, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OZh9_JaPKTE",
        "colab_type": "code",
        "outputId": "ec22851f-abf4-4941-ca2a-fdce46dc2057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>gender_female</th>\n",
              "      <th>gender_male</th>\n",
              "      <th>imagequality_Average</th>\n",
              "      <th>imagequality_Bad</th>\n",
              "      <th>imagequality_Good</th>\n",
              "      <th>age_15-25</th>\n",
              "      <th>age_25-35</th>\n",
              "      <th>age_35-45</th>\n",
              "      <th>age_45-55</th>\n",
              "      <th>age_55+</th>\n",
              "      <th>weight_normal-healthy</th>\n",
              "      <th>weight_over-weight</th>\n",
              "      <th>weight_slightly-overweight</th>\n",
              "      <th>weight_underweight</th>\n",
              "      <th>carryingbag_Daily/Office/Work Bag</th>\n",
              "      <th>carryingbag_Grocery/Home/Plastic Bag</th>\n",
              "      <th>carryingbag_None</th>\n",
              "      <th>footwear_CantSee</th>\n",
              "      <th>footwear_Fancy</th>\n",
              "      <th>footwear_Normal</th>\n",
              "      <th>emotion_Angry/Serious</th>\n",
              "      <th>emotion_Happy</th>\n",
              "      <th>emotion_Neutral</th>\n",
              "      <th>emotion_Sad</th>\n",
              "      <th>bodypose_Back</th>\n",
              "      <th>bodypose_Front-Frontish</th>\n",
              "      <th>bodypose_Side</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11166</th>\n",
              "      <td>resized/11168.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13528</th>\n",
              "      <td>resized/13530.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8579</th>\n",
              "      <td>resized/8580.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3356</th>\n",
              "      <td>resized/3357.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>resized/230.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              image_path  gender_female  ...  bodypose_Front-Frontish  bodypose_Side\n",
              "11166  resized/11168.jpg              1  ...                        1              0\n",
              "13528  resized/13530.jpg              0  ...                        0              1\n",
              "8579    resized/8580.jpg              0  ...                        0              0\n",
              "3356    resized/3357.jpg              0  ...                        0              0\n",
              "229      resized/230.jpg              1  ...                        1              0\n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDCq2YaOPPmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create train and validation data generators\n",
        "train_gen = PersonDataGenerator(train_df,batch_size=32,\n",
        "                                augmentation=ImageDataGenerator(rescale=1./255,width_shift_range=0.1,\n",
        "\t                                                              height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
        "\t                                                              horizontal_flip=True, fill_mode=\"nearest\", \n",
        "                                                                rotation_range=25,preprocessing_function=get_random_eraser(v_l=0, v_h=1)                                                                 \n",
        "\t                                                                                  ))\n",
        "                       \n",
        "                                                            \n",
        "\t                                                                                      \n",
        "\n",
        "                             \n",
        "                                                        \n",
        "                                                          \n",
        "\n",
        "\n",
        "\n",
        "#train_gen = PersonDataGenerator(train_df, batch_size=32,augmentation=True)\n",
        "                                \n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=32, shuffle=False,\n",
        "                                augmentation=ImageDataGenerator(rescale=1./255))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywEcmc1WPXAo",
        "colab_type": "code",
        "outputId": "e0347419-aa8d-4100-a8d0-5d0fdaeb6121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(valid_gen))\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
        "num_units"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': 5,\n",
              " 'bag': 3,\n",
              " 'emotion': 4,\n",
              " 'footwear': 3,\n",
              " 'gender': 2,\n",
              " 'image_quality': 3,\n",
              " 'pose': 3,\n",
              " 'weight': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eDTNKiHPezl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from classification_models.resnet import ResNet18, preprocess_input\n",
        "import keras.applications.resnet \n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "from keras.applications.resnet import ResNet50\n",
        "\n",
        "backbone = InceptionV3(\n",
        "    weights=None, \n",
        "    include_top=False, \n",
        "    input_tensor=Input(shape=(224, 224, 3))\n",
        ")\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "neck = backbone.output\n",
        "neck = Flatten(name=\"flatten\")(neck)\n",
        "neck = Dense(512, activation=\"relu\")(neck)\n",
        "\n",
        "\n",
        "def build_tower(in_layer):\n",
        "    neck = BatchNormalization(momentum=0.355)(in_layer)\n",
        "    neck = Dropout(0.092)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    neck = BatchNormalization(momentum=0.355)(in_layer)\n",
        "    neck = Dropout(0.092)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    neck = BatchNormalization(momentum=0.355)(in_layer)\n",
        "    neck = Dropout(0.092)(in_layer)\n",
        "    neck = Dense(28, activation=\"relu\")(neck)\n",
        "    \n",
        "    \n",
        "    return neck\n",
        "\n",
        "\n",
        "def build_head(name, in_layer):\n",
        "    return Dense(\n",
        "        num_units[name], activation=\"sigmoid\",name=f\"{name}_output\"\n",
        "    )(in_layer)\n",
        "\n",
        "# heads\n",
        "gender = build_head(\"gender\", build_tower(neck))\n",
        "image_quality = build_head(\"image_quality\", build_tower(neck))\n",
        "age = build_head(\"age\", build_tower(neck))\n",
        "weight = build_head(\"weight\", build_tower(neck))\n",
        "bag = build_head(\"bag\", build_tower(neck))\n",
        "footwear = build_head(\"footwear\", build_tower(neck))\n",
        "emotion = build_head(\"emotion\", build_tower(neck))\n",
        "pose = build_head(\"pose\", build_tower(neck))\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    inputs=backbone.input, \n",
        "    outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion]\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD1Y2NC8PsWf",
        "colab_type": "code",
        "outputId": "f1ec4510-f47c-4061-c56b-e2253bb1630a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "losses = {\n",
        " \t\"gender_output\": \"binary_crossentropy\",\n",
        " \t\"image_quality_output\": \"binary_crossentropy\",\n",
        " \t\"age_output\": \"binary_crossentropy\",\n",
        " \t\"weight_output\": \"binary_crossentropy\",\n",
        "  \"bag_output\": \"binary_crossentropy\",\n",
        "  \"pose_output\": \"binary_crossentropy\",\n",
        "  \"footwear_output\": \"binary_crossentropy\",   \n",
        "  \"emotion_output\": \"binary_crossentropy\",\n",
        "       \n",
        "\n",
        " }\n",
        "loss_weights = {\"gender_output\": 0.1, \"image_quality_output\": 0.1, \"age_output\": 0.1, \"weight_output\": 0.1,\"bag_output\":0.1,\"pose_output\":0.1,\"footwear_output\":0.1,\"emotion_output\":0.1}\n",
        "model.summary()\n",
        "\n",
        "opt = SGD(lr=0.0142,momentum=0.9)\n",
        "#opt = tf.train.MomentumOptimizer(lr=lr_schedule(epoch+1),momentum=MOMENTUM,use_nesterov=False)\n",
        "#opt.( global_step=global_step)\n",
        "import os\n",
        "from keras.models import Model\n",
        "# Prepare model model saving directory.\n",
        "save_dir = '/content/gdrive/My Drive/EIP4/SaveModel'\n",
        "filepath = '/content/gdrive/My Drive/EIP4/SaveModel/model95.h5'\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_loss',\n",
        "                             verbose=0,\n",
        "                             save_best_only=True)\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"binary_crossentropy\", \n",
        "    #from_logits=True,\n",
        "    #loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    loss_weights=loss_weights, \n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "import os\n",
        "from keras.models import Model\n",
        "# Prepare model model saving directory.\n",
        "save_dir = '/content/gdrive/My Drive/EIP4/SaveModel'\n",
        "filepath = '/content/gdrive/My Drive/EIP4/SaveModel/model90.h5'\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_loss',\n",
        "                             verbose=0,\n",
        "                             save_best_only=True)\n",
        "callbacks = [checkpoint]\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 111, 111, 32) 864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 111, 111, 32) 96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 111, 111, 32) 0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 109, 109, 32) 9216        activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 109, 109, 32) 96          conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 109, 109, 32) 0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 109, 109, 64) 18432       activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 109, 109, 64) 192         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 109, 109, 64) 0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 54, 54, 80)   5120        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 54, 54, 80)   240         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 54, 54, 80)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 52, 52, 192)  138240      activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 52, 52, 192)  576         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 52, 52, 192)  0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 25, 25, 64)   192         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 25, 25, 64)   0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 25, 25, 96)   55296       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 25, 25, 48)   144         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 25, 25, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 25, 25, 48)   0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 25, 25, 96)   0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 25, 25, 64)   76800       activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 25, 25, 96)   82944       activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 25, 25, 64)   192         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 25, 25, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 25, 25, 96)   288         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 25, 25, 32)   96          conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 25, 25, 64)   0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 25, 25, 64)   0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 25, 25, 96)   0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 25, 25, 32)   0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_100[0][0]             \n",
            "                                                                 activation_102[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "                                                                 activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 25, 25, 64)   192         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 25, 25, 64)   0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 25, 25, 96)   55296       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 25, 25, 48)   144         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 25, 25, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 25, 25, 48)   0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 25, 25, 96)   0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 25, 25, 64)   76800       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 25, 25, 96)   82944       activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 25, 25, 64)   192         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 25, 25, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 25, 25, 96)   288         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 25, 25, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 25, 25, 64)   0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 25, 25, 64)   0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 25, 25, 96)   0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 25, 25, 64)   0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_107[0][0]             \n",
            "                                                                 activation_109[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "                                                                 activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 25, 25, 64)   192         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 25, 25, 64)   0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 25, 25, 96)   55296       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 25, 25, 48)   144         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 25, 25, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 25, 25, 48)   0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 25, 25, 96)   0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 25, 25, 64)   76800       activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 25, 25, 96)   82944       activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 25, 25, 64)   192         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 25, 25, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 25, 25, 96)   288         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 25, 25, 64)   192         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 25, 25, 64)   0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 25, 25, 64)   0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 25, 25, 96)   0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 25, 25, 64)   0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_114[0][0]             \n",
            "                                                                 activation_116[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "                                                                 activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 25, 25, 64)   192         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 25, 25, 64)   0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 25, 25, 96)   55296       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 25, 25, 96)   288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 25, 25, 96)   0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 12, 12, 96)   82944       activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 12, 12, 384)  1152        conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 12, 12, 96)   288         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 12, 12, 384)  0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 12, 12, 96)   0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_121[0][0]             \n",
            "                                                                 activation_124[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 12, 12, 128)  384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 12, 12, 128)  0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 12, 12, 128)  114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 12, 12, 128)  384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 12, 12, 128)  0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 12, 12, 128)  114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 12, 12, 128)  384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 12, 12, 128)  384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 12, 12, 128)  0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 12, 12, 128)  0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 12, 12, 128)  114688      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 12, 12, 128)  114688      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 12, 12, 128)  384         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 12, 12, 128)  384         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 12, 12, 128)  0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 12, 12, 128)  0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 12, 12, 192)  172032      activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 12, 12, 192)  172032      activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 12, 12, 192)  576         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 12, 12, 192)  576         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 12, 12, 192)  576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 12, 12, 192)  576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 12, 12, 192)  0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 12, 12, 192)  0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 12, 12, 192)  0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 12, 12, 192)  0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_125[0][0]             \n",
            "                                                                 activation_128[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "                                                                 activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 12, 12, 160)  480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 12, 12, 160)  0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 12, 12, 160)  179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 12, 12, 160)  480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 12, 12, 160)  0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 12, 12, 160)  179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 12, 12, 160)  480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 12, 12, 160)  480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 12, 12, 160)  0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 12, 12, 160)  0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 12, 12, 160)  179200      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 12, 12, 160)  179200      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 12, 12, 160)  480         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 12, 12, 160)  480         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 12, 12, 160)  0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 12, 12, 160)  0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 12, 12, 192)  215040      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 12, 12, 192)  215040      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 12, 12, 192)  576         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 12, 12, 192)  576         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 12, 12, 192)  576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 12, 12, 192)  576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 12, 12, 192)  0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 12, 12, 192)  0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 12, 12, 192)  0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 12, 12, 192)  0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_135[0][0]             \n",
            "                                                                 activation_138[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "                                                                 activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 12, 12, 160)  480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 12, 12, 160)  0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 12, 12, 160)  179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 12, 12, 160)  480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 12, 12, 160)  0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 12, 12, 160)  179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 12, 12, 160)  480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 12, 12, 160)  480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 12, 12, 160)  0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 12, 12, 160)  0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 12, 12, 160)  179200      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 12, 12, 160)  179200      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 12, 12, 160)  480         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 12, 12, 160)  480         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 12, 12, 160)  0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 12, 12, 160)  0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 12, 12, 192)  215040      activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 12, 12, 192)  215040      activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 12, 12, 192)  576         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 12, 12, 192)  576         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 12, 12, 192)  576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 12, 12, 192)  576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 12, 12, 192)  0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 12, 12, 192)  0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 12, 12, 192)  0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 12, 12, 192)  0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_145[0][0]             \n",
            "                                                                 activation_148[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "                                                                 activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 12, 12, 192)  576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 12, 12, 192)  0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 12, 12, 192)  258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 12, 12, 192)  576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 12, 12, 192)  0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 12, 12, 192)  258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 12, 12, 192)  576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 12, 12, 192)  576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 12, 12, 192)  0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 12, 12, 192)  0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 12, 12, 192)  258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 12, 12, 192)  258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 12, 12, 192)  576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 12, 12, 192)  576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 12, 12, 192)  0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 12, 12, 192)  0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 12, 12, 192)  258048      activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 12, 12, 192)  258048      activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 12, 12, 192)  576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 12, 12, 192)  576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 12, 12, 192)  576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 12, 12, 192)  576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 12, 12, 192)  0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 12, 12, 192)  0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 12, 12, 192)  0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 12, 12, 192)  0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_155[0][0]             \n",
            "                                                                 activation_158[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "                                                                 activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 12, 12, 192)  576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 12, 12, 192)  0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 12, 12, 192)  258048      activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 12, 12, 192)  576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 12, 12, 192)  0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 12, 12, 192)  258048      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 12, 12, 192)  576         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 12, 12, 192)  576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 12, 12, 192)  0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 12, 12, 192)  0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 5, 5, 320)    552960      activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 5, 5, 192)    331776      activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 5, 5, 320)    960         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 5, 5, 192)    576         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 5, 5, 320)    0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 5, 5, 192)    0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_166[0][0]             \n",
            "                                                                 activation_170[0][0]             \n",
            "                                                                 max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 5, 5, 448)    1344        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 5, 5, 448)    0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 5, 5, 384)    1548288     activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 5, 5, 384)    1152        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 5, 5, 384)    1152        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 5, 5, 384)    0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 5, 5, 384)    0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 5, 5, 384)    442368      activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 5, 5, 384)    442368      activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 5, 5, 384)    442368      activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 5, 5, 384)    442368      activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 5, 5, 384)    1152        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 5, 5, 384)    1152        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 5, 5, 384)    1152        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 5, 5, 384)    1152        conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 5, 5, 320)    960         conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 5, 5, 384)    0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 5, 5, 384)    0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 5, 5, 384)    0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 5, 5, 384)    0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 5, 5, 192)    576         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 5, 5, 320)    0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_173[0][0]             \n",
            "                                                                 activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 5, 5, 768)    0           activation_177[0][0]             \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 5, 5, 192)    0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_171[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 5, 5, 448)    1344        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 5, 5, 448)    0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 5, 5, 384)    1548288     activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 5, 5, 384)    1152        conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 5, 5, 384)    1152        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 5, 5, 384)    0           batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 5, 5, 384)    0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 5, 5, 384)    442368      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 5, 5, 384)    442368      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 5, 5, 384)    442368      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 5, 5, 384)    442368      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_18 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 5, 5, 384)    1152        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 5, 5, 384)    1152        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 5, 5, 384)    1152        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 5, 5, 384)    1152        conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 5, 5, 320)    960         conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 5, 5, 384)    0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 5, 5, 384)    0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 5, 5, 384)    0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 5, 5, 384)    0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 5, 5, 192)    576         conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 5, 5, 320)    0           batch_normalization_204[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_182[0][0]             \n",
            "                                                                 activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 5, 5, 768)    0           activation_186[0][0]             \n",
            "                                                                 activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 5, 5, 192)    0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_180[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_4[0][0]              \n",
            "                                                                 activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 51200)        0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_26 (Dense)                (None, 512)          26214912    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 512)          0           dense_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 512)          0           dense_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_33 (Dropout)            (None, 512)          0           dense_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_36 (Dropout)            (None, 512)          0           dense_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 512)          0           dense_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 512)          0           dense_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 512)          0           dense_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 512)          0           dense_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_29 (Dense)                (None, 28)           14364       dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_32 (Dense)                (None, 28)           14364       dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_35 (Dense)                (None, 28)           14364       dropout_33[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_38 (Dense)                (None, 28)           14364       dropout_36[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_41 (Dense)                (None, 28)           14364       dropout_39[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_44 (Dense)                (None, 28)           14364       dropout_42[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_50 (Dense)                (None, 28)           14364       dropout_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_47 (Dense)                (None, 28)           14364       dropout_45[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "gender_output (Dense)           (None, 2)            58          dense_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "image_quality_output (Dense)    (None, 3)            87          dense_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "age_output (Dense)              (None, 5)            145         dense_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "weight_output (Dense)           (None, 4)            116         dense_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bag_output (Dense)              (None, 3)            87          dense_41[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "footwear_output (Dense)         (None, 3)            87          dense_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pose_output (Dense)             (None, 3)            87          dense_50[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "emotion_output (Dense)          (None, 4)            116         dense_47[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 48,133,391\n",
            "Trainable params: 48,098,959\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v1jARuRP0-1",
        "colab_type": "code",
        "outputId": "576b4055-998a-4966-881e-936d9406e569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    workers=4, \n",
        "    epochs=200,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "360/360 [==============================] - 177s 491ms/step - loss: 0.4332 - gender_output_loss: 0.6908 - image_quality_output_loss: 0.5897 - age_output_loss: 0.4713 - weight_output_loss: 0.4358 - bag_output_loss: 0.5614 - footwear_output_loss: 0.6179 - pose_output_loss: 0.5618 - emotion_output_loss: 0.4036 - gender_output_acc: 0.5512 - image_quality_output_acc: 0.6924 - age_output_acc: 0.7949 - weight_output_acc: 0.8099 - bag_output_acc: 0.7033 - footwear_output_acc: 0.6607 - pose_output_acc: 0.7364 - emotion_output_acc: 0.8504 - val_loss: 0.4222 - val_gender_output_loss: 0.6773 - val_image_quality_output_loss: 0.5847 - val_age_output_loss: 0.4623 - val_weight_output_loss: 0.4244 - val_bag_output_loss: 0.5543 - val_footwear_output_loss: 0.5837 - val_pose_output_loss: 0.5411 - val_emotion_output_loss: 0.3944 - val_gender_output_acc: 0.5615 - val_image_quality_output_acc: 0.6910 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8109 - val_bag_output_acc: 0.6951 - val_footwear_output_acc: 0.6901 - val_pose_output_acc: 0.7508 - val_emotion_output_acc: 0.8521\n",
            "Epoch 2/200\n",
            "360/360 [==============================] - 150s 416ms/step - loss: 0.4222 - gender_output_loss: 0.6741 - image_quality_output_loss: 0.5807 - age_output_loss: 0.4598 - weight_output_loss: 0.4256 - bag_output_loss: 0.5490 - footwear_output_loss: 0.5929 - pose_output_loss: 0.5506 - emotion_output_loss: 0.3892 - gender_output_acc: 0.5614 - image_quality_output_acc: 0.6960 - age_output_acc: 0.7991 - weight_output_acc: 0.8162 - bag_output_acc: 0.7082 - footwear_output_acc: 0.6793 - pose_output_acc: 0.7436 - emotion_output_acc: 0.8566 - val_loss: 0.4167 - val_gender_output_loss: 0.6698 - val_image_quality_output_loss: 0.5785 - val_age_output_loss: 0.4557 - val_weight_output_loss: 0.4200 - val_bag_output_loss: 0.5542 - val_footwear_output_loss: 0.5573 - val_pose_output_loss: 0.5394 - val_emotion_output_loss: 0.3923 - val_gender_output_acc: 0.5816 - val_image_quality_output_acc: 0.6991 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8185 - val_bag_output_acc: 0.6948 - val_footwear_output_acc: 0.7113 - val_pose_output_acc: 0.7513 - val_emotion_output_acc: 0.8522\n",
            "Epoch 3/200\n",
            "360/360 [==============================] - 146s 406ms/step - loss: 0.4197 - gender_output_loss: 0.6679 - image_quality_output_loss: 0.5784 - age_output_loss: 0.4580 - weight_output_loss: 0.4233 - bag_output_loss: 0.5468 - footwear_output_loss: 0.5853 - pose_output_loss: 0.5491 - emotion_output_loss: 0.3880 - gender_output_acc: 0.5724 - image_quality_output_acc: 0.6997 - age_output_acc: 0.7995 - weight_output_acc: 0.8170 - bag_output_acc: 0.7100 - footwear_output_acc: 0.6847 - pose_output_acc: 0.7438 - emotion_output_acc: 0.8563 - val_loss: 0.4141 - val_gender_output_loss: 0.6574 - val_image_quality_output_loss: 0.5786 - val_age_output_loss: 0.4527 - val_weight_output_loss: 0.4183 - val_bag_output_loss: 0.5484 - val_footwear_output_loss: 0.5557 - val_pose_output_loss: 0.5395 - val_emotion_output_loss: 0.3908 - val_gender_output_acc: 0.6057 - val_image_quality_output_acc: 0.6964 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8181 - val_bag_output_acc: 0.6958 - val_footwear_output_acc: 0.7116 - val_pose_output_acc: 0.7513 - val_emotion_output_acc: 0.8522\n",
            "Epoch 4/200\n",
            "360/360 [==============================] - 145s 404ms/step - loss: 0.4178 - gender_output_loss: 0.6613 - image_quality_output_loss: 0.5789 - age_output_loss: 0.4569 - weight_output_loss: 0.4227 - bag_output_loss: 0.5448 - footwear_output_loss: 0.5785 - pose_output_loss: 0.5484 - emotion_output_loss: 0.3860 - gender_output_acc: 0.5907 - image_quality_output_acc: 0.7004 - age_output_acc: 0.7994 - weight_output_acc: 0.8169 - bag_output_acc: 0.7111 - footwear_output_acc: 0.6938 - pose_output_acc: 0.7438 - emotion_output_acc: 0.8566 - val_loss: 0.4124 - val_gender_output_loss: 0.6506 - val_image_quality_output_loss: 0.5785 - val_age_output_loss: 0.4525 - val_weight_output_loss: 0.4184 - val_bag_output_loss: 0.5471 - val_footwear_output_loss: 0.5467 - val_pose_output_loss: 0.5381 - val_emotion_output_loss: 0.3915 - val_gender_output_acc: 0.6101 - val_image_quality_output_acc: 0.6989 - val_age_output_acc: 0.7996 - val_weight_output_acc: 0.8176 - val_bag_output_acc: 0.6976 - val_footwear_output_acc: 0.7206 - val_pose_output_acc: 0.7513 - val_emotion_output_acc: 0.8522\n",
            "Epoch 5/200\n",
            "360/360 [==============================] - 145s 404ms/step - loss: 0.4157 - gender_output_loss: 0.6527 - image_quality_output_loss: 0.5778 - age_output_loss: 0.4559 - weight_output_loss: 0.4219 - bag_output_loss: 0.5425 - footwear_output_loss: 0.5716 - pose_output_loss: 0.5480 - emotion_output_loss: 0.3869 - gender_output_acc: 0.6034 - image_quality_output_acc: 0.6995 - age_output_acc: 0.7998 - weight_output_acc: 0.8174 - bag_output_acc: 0.7129 - footwear_output_acc: 0.6961 - pose_output_acc: 0.7439 - emotion_output_acc: 0.8565 - val_loss: 0.4153 - val_gender_output_loss: 0.6790 - val_image_quality_output_loss: 0.5769 - val_age_output_loss: 0.4529 - val_weight_output_loss: 0.4196 - val_bag_output_loss: 0.5474 - val_footwear_output_loss: 0.5496 - val_pose_output_loss: 0.5386 - val_emotion_output_loss: 0.3886 - val_gender_output_acc: 0.5434 - val_image_quality_output_acc: 0.6999 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8185 - val_bag_output_acc: 0.7011 - val_footwear_output_acc: 0.7136 - val_pose_output_acc: 0.7513 - val_emotion_output_acc: 0.8522\n",
            "Epoch 6/200\n",
            "360/360 [==============================] - 155s 429ms/step - loss: 0.4146 - gender_output_loss: 0.6484 - image_quality_output_loss: 0.5770 - age_output_loss: 0.4560 - weight_output_loss: 0.4211 - bag_output_loss: 0.5414 - footwear_output_loss: 0.5704 - pose_output_loss: 0.5464 - emotion_output_loss: 0.3860 - gender_output_acc: 0.6133 - image_quality_output_acc: 0.7015 - age_output_acc: 0.7996 - weight_output_acc: 0.8159 - bag_output_acc: 0.7137 - footwear_output_acc: 0.7013 - pose_output_acc: 0.7440 - emotion_output_acc: 0.8569 - val_loss: 0.4085 - val_gender_output_loss: 0.6328 - val_image_quality_output_loss: 0.5785 - val_age_output_loss: 0.4507 - val_weight_output_loss: 0.4182 - val_bag_output_loss: 0.5419 - val_footwear_output_loss: 0.5377 - val_pose_output_loss: 0.5356 - val_emotion_output_loss: 0.3897 - val_gender_output_acc: 0.6310 - val_image_quality_output_acc: 0.6997 - val_age_output_acc: 0.8003 - val_weight_output_acc: 0.8182 - val_bag_output_acc: 0.7035 - val_footwear_output_acc: 0.7259 - val_pose_output_acc: 0.7513 - val_emotion_output_acc: 0.8522\n",
            "Epoch 7/200\n",
            "360/360 [==============================] - 155s 430ms/step - loss: 0.4130 - gender_output_loss: 0.6430 - image_quality_output_loss: 0.5760 - age_output_loss: 0.4545 - weight_output_loss: 0.4209 - bag_output_loss: 0.5387 - footwear_output_loss: 0.5664 - pose_output_loss: 0.5452 - emotion_output_loss: 0.3857 - gender_output_acc: 0.6173 - image_quality_output_acc: 0.7014 - age_output_acc: 0.7999 - weight_output_acc: 0.8172 - bag_output_acc: 0.7170 - footwear_output_acc: 0.7031 - pose_output_acc: 0.7439 - emotion_output_acc: 0.8565 - val_loss: 0.4154 - val_gender_output_loss: 0.6477 - val_image_quality_output_loss: 0.5836 - val_age_output_loss: 0.4592 - val_weight_output_loss: 0.4241 - val_bag_output_loss: 0.5429 - val_footwear_output_loss: 0.5524 - val_pose_output_loss: 0.5426 - val_emotion_output_loss: 0.4017 - val_gender_output_acc: 0.6218 - val_image_quality_output_acc: 0.6944 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8177 - val_bag_output_acc: 0.7054 - val_footwear_output_acc: 0.7143 - val_pose_output_acc: 0.7513 - val_emotion_output_acc: 0.8478\n",
            "Epoch 8/200\n",
            "360/360 [==============================] - 155s 431ms/step - loss: 0.4116 - gender_output_loss: 0.6365 - image_quality_output_loss: 0.5756 - age_output_loss: 0.4542 - weight_output_loss: 0.4211 - bag_output_loss: 0.5378 - footwear_output_loss: 0.5621 - pose_output_loss: 0.5431 - emotion_output_loss: 0.3851 - gender_output_acc: 0.6285 - image_quality_output_acc: 0.7027 - age_output_acc: 0.7991 - weight_output_acc: 0.8169 - bag_output_acc: 0.7184 - footwear_output_acc: 0.7036 - pose_output_acc: 0.7442 - emotion_output_acc: 0.8566 - val_loss: 0.4099 - val_gender_output_loss: 0.6196 - val_image_quality_output_loss: 0.5796 - val_age_output_loss: 0.4578 - val_weight_output_loss: 0.4231 - val_bag_output_loss: 0.5430 - val_footwear_output_loss: 0.5421 - val_pose_output_loss: 0.5363 - val_emotion_output_loss: 0.3973 - val_gender_output_acc: 0.6570 - val_image_quality_output_acc: 0.6986 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8162 - val_bag_output_acc: 0.7159 - val_footwear_output_acc: 0.7287 - val_pose_output_acc: 0.7517 - val_emotion_output_acc: 0.8522\n",
            "Epoch 9/200\n",
            "197/360 [===============>..............] - ETA: 1:06 - loss: 0.4100 - gender_output_loss: 0.6334 - image_quality_output_loss: 0.5757 - age_output_loss: 0.4531 - weight_output_loss: 0.4228 - bag_output_loss: 0.5334 - footwear_output_loss: 0.5594 - pose_output_loss: 0.5412 - emotion_output_loss: 0.3809 - gender_output_acc: 0.6326 - image_quality_output_acc: 0.7019 - age_output_acc: 0.7999 - weight_output_acc: 0.8130 - bag_output_acc: 0.7241 - footwear_output_acc: 0.7088 - pose_output_acc: 0.7477 - emotion_output_acc: 0.8590Epoch 1/200\n",
            "360/360 [==============================] - 177s 491ms/step - loss: 0.4332 - gender_output_loss: 0.6908 - image_quality_output_loss: 0.5897 - age_output_loss: 0.4713 - weight_output_loss: 0.4358 - bag_output_loss: 0.5614 - footwear_output_loss: 0.6179 - pose_output_loss: 0.5618 - emotion_output_loss: 0.4036 - gender_output_acc: 0.5512 - image_quality_output_acc: 0.6924 - age_output_acc: 0.7949 - weight_output_acc: 0.8099 - bag_output_acc: 0.7033 - footwear_output_acc: 0.6607 - pose_output_acc: 0.7364 - emotion_output_acc: 0.8504 - val_loss: 0.4222 - val_gender_output_loss: 0.6773 - val_image_quality_output_loss: 0.5847 - val_age_output_loss: 0.4623 - val_weight_output_loss: 0.4244 - val_bag_output_loss: 0.5543 - val_footwear_output_loss: 0.5837 - val_pose_output_loss: 0.5411 - val_emotion_output_loss: 0.3944 - val_gender_output_acc: 0.5615 - val_image_quality_output_acc: 0.6910 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8109 - val_bag_output_acc: 0.6951 - val_footwear_output_acc: 0.6901 - val_pose_output_acc: 0.7508 - val_emotion_output_acc: 0.8521\n",
            "Epoch 2/200\n",
            "360/360 [==============================] - 150s 416ms/step - loss: 0.4222 - gender_output_loss: 0.6741 - image_quality_output_loss: 0.5807 - age_output_loss: 0.4598 - weight_output_loss: 0.4256 - bag_output_loss: 0.5490 - footwear_output_loss: 0.5929 - pose_output_loss: 0.5506 - emotion_output_loss: 0.3892 - gender_output_acc: 0.5614 - image_quality_output_acc: 0.6960 - age_output_acc: 0.7991 - weight_output_acc: 0.8162 - bag_output_acc: 0.7082 - footwear_output_acc: 0.6793 - pose_output_acc: 0.7436 - emotion_output_acc: 0.8566 - val_loss: 0.4167 - val_gender_output_loss: 0.6698 - val_image_quality_output_loss: 0.5785 - val_age_output_loss: 0.4557 - val_weight_output_loss: 0.4200 - val_bag_output_loss: 0.5542 - val_footwear_output_loss: 0.5573 - val_pose_output_loss: 0.5394 - val_emotion_output_loss: 0.3923 - val_gender_output_acc: 0.5816 - val_image_quality_output_acc: 0.6991 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8185 - val_bag_output_acc: 0.6948 - val_footwear_output_acc: 0.7113 - val_pose_output_acc: 0.7513 - val_emotion_output_acc: 0.8522\n",
            "Epoch 3/200\n",
            "360/360 [==============================] - 146s 406ms/step - loss: 0.4197 - gender_output_loss: 0.6679 - image_quality_output_loss: 0.5784 - age_output_loss: 0.4580 - weight_output_loss: 0.4233 - bag_output_loss: 0.5468 - footwear_output_loss: 0.5853 - pose_output_loss: 0.5491 - emotion_output_loss: 0.3880 - gender_output_acc: 0.5724 - image_quality_output_acc: 0.6997 - age_output_acc: 0.7995 - weight_output_acc: 0.8170 - bag_output_acc: 0.7100 - footwear_output_acc: 0.6847 - pose_output_acc: 0.7438 - emotion_output_acc: 0.8563 - val_loss: 0.4141 - val_gender_output_loss: 0.6574 - val_image_quality_output_loss: 0.5786 - val_age_output_loss: 0.4527 - val_weight_output_loss: 0.4183 - val_bag_output_loss: 0.5484 - val_footwear_output_loss: 0.5557 - val_pose_output_loss: 0.5395 - val_emotion_output_loss: 0.3908 - val_gender_output_acc: 0.6057 - val_image_quality_output_acc: 0.6964 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8181 - val_bag_output_acc: 0.6958 - val_footwear_output_acc: 0.7116 - val_pose_output_acc: 0.7513 - val_emotion_output_acc: 0.8522\n",
            "Epoch 4/200\n",
            "360/360 [==============================] - 145s 404ms/step - loss: 0.4178 - gender_output_loss: 0.6613 - image_quality_output_loss: 0.5789 - age_output_loss: 0.4569 - weight_output_loss: 0.4227 - bag_output_loss: 0.5448 - footwear_output_loss: 0.5785 - pose_output_loss: 0.5484 - emotion_output_loss: 0.3860 - gender_output_acc: 0.5907 - image_quality_output_acc: 0.7004 - age_output_acc: 0.7994 - weight_output_acc: 0.8169 - bag_output_acc: 0.7111 - footwear_output_acc: 0.6938 - pose_output_acc: 0.7438 - emotion_output_acc: 0.8566 - val_loss: 0.4124 - val_gender_output_loss: 0.6506 - val_image_quality_output_loss: 0.5785 - val_age_output_loss: 0.4525 - val_weight_output_loss: 0.4184 - val_bag_output_loss: 0.5471 - val_footwear_output_loss: 0.5467 - val_pose_output_loss: 0.5381 - val_emotion_output_loss: 0.3915 - val_gender_output_acc: 0.6101 - val_image_quality_output_acc: 0.6989 - val_age_output_acc: 0.7996 - val_weight_output_acc: 0.8176 - val_bag_output_acc: 0.6976 - val_footwear_output_acc: 0.7206 - val_pose_output_acc: 0.7513 - val_emotion_output_acc: 0.8522\n",
            "Epoch 5/200\n",
            "360/360 [==============================] - 145s 404ms/step - loss: 0.4157 - gender_output_loss: 0.6527 - image_quality_output_loss: 0.5778 - age_output_loss: 0.4559 - weight_output_loss: 0.4219 - bag_output_loss: 0.5425 - footwear_output_loss: 0.5716 - pose_output_loss: 0.5480 - emotion_output_loss: 0.3869 - gender_output_acc: 0.6034 - image_quality_output_acc: 0.6995 - age_output_acc: 0.7998 - weight_output_acc: 0.8174 - bag_output_acc: 0.7129 - footwear_output_acc: 0.6961 - pose_output_acc: 0.7439 - emotion_output_acc: 0.8565 - val_loss: 0.4153 - val_gender_output_loss: 0.6790 - val_image_quality_output_loss: 0.5769 - val_age_output_loss: 0.4529 - val_weight_output_loss: 0.4196 - val_bag_output_loss: 0.5474 - val_footwear_output_loss: 0.5496 - val_pose_output_loss: 0.5386 - val_emotion_output_loss: 0.3886 - val_gender_output_acc: 0.5434 - val_image_quality_output_acc: 0.6999 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8185 - val_bag_output_acc: 0.7011 - val_footwear_output_acc: 0.7136 - val_pose_output_acc: 0.7513 - val_emotion_output_acc: 0.8522\n",
            "Epoch 6/200\n",
            "360/360 [==============================] - 155s 429ms/step - loss: 0.4146 - gender_output_loss: 0.6484 - image_quality_output_loss: 0.5770 - age_output_loss: 0.4560 - weight_output_loss: 0.4211 - bag_output_loss: 0.5414 - footwear_output_loss: 0.5704 - pose_output_loss: 0.5464 - emotion_output_loss: 0.3860 - gender_output_acc: 0.6133 - image_quality_output_acc: 0.7015 - age_output_acc: 0.7996 - weight_output_acc: 0.8159 - bag_output_acc: 0.7137 - footwear_output_acc: 0.7013 - pose_output_acc: 0.7440 - emotion_output_acc: 0.8569 - val_loss: 0.4085 - val_gender_output_loss: 0.6328 - val_image_quality_output_loss: 0.5785 - val_age_output_loss: 0.4507 - val_weight_output_loss: 0.4182 - val_bag_output_loss: 0.5419 - val_footwear_output_loss: 0.5377 - val_pose_output_loss: 0.5356 - val_emotion_output_loss: 0.3897 - val_gender_output_acc: 0.6310 - val_image_quality_output_acc: 0.6997 - val_age_output_acc: 0.8003 - val_weight_output_acc: 0.8182 - val_bag_output_acc: 0.7035 - val_footwear_output_acc: 0.7259 - val_pose_output_acc: 0.7513 - val_emotion_output_acc: 0.8522\n",
            "Epoch 7/200\n",
            "360/360 [==============================] - 155s 430ms/step - loss: 0.4130 - gender_output_loss: 0.6430 - image_quality_output_loss: 0.5760 - age_output_loss: 0.4545 - weight_output_loss: 0.4209 - bag_output_loss: 0.5387 - footwear_output_loss: 0.5664 - pose_output_loss: 0.5452 - emotion_output_loss: 0.3857 - gender_output_acc: 0.6173 - image_quality_output_acc: 0.7014 - age_output_acc: 0.7999 - weight_output_acc: 0.8172 - bag_output_acc: 0.7170 - footwear_output_acc: 0.7031 - pose_output_acc: 0.7439 - emotion_output_acc: 0.8565 - val_loss: 0.4154 - val_gender_output_loss: 0.6477 - val_image_quality_output_loss: 0.5836 - val_age_output_loss: 0.4592 - val_weight_output_loss: 0.4241 - val_bag_output_loss: 0.5429 - val_footwear_output_loss: 0.5524 - val_pose_output_loss: 0.5426 - val_emotion_output_loss: 0.4017 - val_gender_output_acc: 0.6218 - val_image_quality_output_acc: 0.6944 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8177 - val_bag_output_acc: 0.7054 - val_footwear_output_acc: 0.7143 - val_pose_output_acc: 0.7513 - val_emotion_output_acc: 0.8478\n",
            "Epoch 8/200\n",
            "360/360 [==============================] - 155s 431ms/step - loss: 0.4116 - gender_output_loss: 0.6365 - image_quality_output_loss: 0.5756 - age_output_loss: 0.4542 - weight_output_loss: 0.4211 - bag_output_loss: 0.5378 - footwear_output_loss: 0.5621 - pose_output_loss: 0.5431 - emotion_output_loss: 0.3851 - gender_output_acc: 0.6285 - image_quality_output_acc: 0.7027 - age_output_acc: 0.7991 - weight_output_acc: 0.8169 - bag_output_acc: 0.7184 - footwear_output_acc: 0.7036 - pose_output_acc: 0.7442 - emotion_output_acc: 0.8566 - val_loss: 0.4099 - val_gender_output_loss: 0.6196 - val_image_quality_output_loss: 0.5796 - val_age_output_loss: 0.4578 - val_weight_output_loss: 0.4231 - val_bag_output_loss: 0.5430 - val_footwear_output_loss: 0.5421 - val_pose_output_loss: 0.5363 - val_emotion_output_loss: 0.3973 - val_gender_output_acc: 0.6570 - val_image_quality_output_acc: 0.6986 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8162 - val_bag_output_acc: 0.7159 - val_footwear_output_acc: 0.7287 - val_pose_output_acc: 0.7517 - val_emotion_output_acc: 0.8522\n",
            "Epoch 9/200\n",
            "360/360 [==============================] - 153s 424ms/step - loss: 0.4099 - gender_output_loss: 0.6298 - image_quality_output_loss: 0.5751 - age_output_loss: 0.4536 - weight_output_loss: 0.4197 - bag_output_loss: 0.5355 - footwear_output_loss: 0.5591 - pose_output_loss: 0.5417 - emotion_output_loss: 0.3850 - gender_output_acc: 0.6390 - image_quality_output_acc: 0.7025 - age_output_acc: 0.7998 - weight_output_acc: 0.8168 - bag_output_acc: 0.7210 - footwear_output_acc: 0.7107 - pose_output_acc: 0.7447 - emotion_output_acc: 0.8564 - val_loss: 0.4045 - val_gender_output_loss: 0.6145 - val_image_quality_output_loss: 0.5754 - val_age_output_loss: 0.4513 - val_weight_output_loss: 0.4178 - val_bag_output_loss: 0.5371 - val_footwear_output_loss: 0.5305 - val_pose_output_loss: 0.5289 - val_emotion_output_loss: 0.3898 - val_gender_output_acc: 0.6687 - val_image_quality_output_acc: 0.6996 - val_age_output_acc: 0.7999 - val_weight_output_acc: 0.8183 - val_bag_output_acc: 0.7163 - val_footwear_output_acc: 0.7348 - val_pose_output_acc: 0.7536 - val_emotion_output_acc: 0.8522\n",
            "360/360 [==============================] - 153s 424ms/step - loss: 0.4099 - gender_output_loss: 0.6298 - image_quality_output_loss: 0.5751 - age_output_loss: 0.4536 - weight_output_loss: 0.4197 - bag_output_loss: 0.5355 - footwear_output_loss: 0.5591 - pose_output_loss: 0.5417 - emotion_output_loss: 0.3850 - gender_output_acc: 0.6390 - image_quality_output_acc: 0.7025 - age_output_acc: 0.7998 - weight_output_acc: 0.8168 - bag_output_acc: 0.7210 - footwear_output_acc: 0.7107 - pose_output_acc: 0.7447 - emotion_output_acc: 0.8564 - val_loss: 0.4045 - val_gender_output_loss: 0.6145 - val_image_quality_output_loss: 0.5754 - val_age_output_loss: 0.4513 - val_weight_output_loss: 0.4178 - val_bag_output_loss: 0.5371 - val_footwear_output_loss: 0.5305 - val_pose_output_loss: 0.5289 - val_emotion_output_loss: 0.3898 - val_gender_output_acc: 0.6687 - val_image_quality_output_acc: 0.6996 - val_age_output_acc: 0.7999 - val_weight_output_acc: 0.8183 - val_bag_output_acc: 0.7163 - val_footwear_output_acc: 0.7348 - val_pose_output_acc: 0.7536 - val_emotion_output_acc: 0.8522\n",
            "Epoch 10/200\n",
            "Epoch 10/200\n",
            "360/360 [==============================] - 150s 416ms/step - loss: 0.4081 - gender_output_loss: 0.6218 - image_quality_output_loss: 0.5753 - age_output_loss: 0.4531 - weight_output_loss: 0.4191 - bag_output_loss: 0.5336 - footwear_output_loss: 0.5542 - pose_output_loss: 0.5397 - emotion_output_loss: 0.3847 - gender_output_acc: 0.6426 - image_quality_output_acc: 0.7021 - age_output_acc: 0.7996 - weight_output_acc: 0.8167 - bag_output_acc: 0.7239 - footwear_output_acc: 0.7124 - pose_output_acc: 0.7446 - emotion_output_acc: 0.8566 - val_loss: 0.4008 - val_gender_output_loss: 0.5967 - val_image_quality_output_loss: 0.5732 - val_age_output_loss: 0.4493 - val_weight_output_loss: 0.4156 - val_bag_output_loss: 0.5344 - val_footwear_output_loss: 0.5238 - val_pose_output_loss: 0.5268 - val_emotion_output_loss: 0.3883 - val_gender_output_acc: 0.6714 - val_image_quality_output_acc: 0.7035 - val_age_output_acc: 0.7999 - val_weight_output_acc: 0.8168 - val_bag_output_acc: 0.7204 - val_footwear_output_acc: 0.7328 - val_pose_output_acc: 0.7520 - val_emotion_output_acc: 0.8521\n",
            "360/360 [==============================] - 150s 416ms/step - loss: 0.4081 - gender_output_loss: 0.6218 - image_quality_output_loss: 0.5753 - age_output_loss: 0.4531 - weight_output_loss: 0.4191 - bag_output_loss: 0.5336 - footwear_output_loss: 0.5542 - pose_output_loss: 0.5397 - emotion_output_loss: 0.3847 - gender_output_acc: 0.6426 - image_quality_output_acc: 0.7021 - age_output_acc: 0.7996 - weight_output_acc: 0.8167 - bag_output_acc: 0.7239 - footwear_output_acc: 0.7124 - pose_output_acc: 0.7446 - emotion_output_acc: 0.8566 - val_loss: 0.4008 - val_gender_output_loss: 0.5967 - val_image_quality_output_loss: 0.5732 - val_age_output_loss: 0.4493 - val_weight_output_loss: 0.4156 - val_bag_output_loss: 0.5344 - val_footwear_output_loss: 0.5238 - val_pose_output_loss: 0.5268 - val_emotion_output_loss: 0.3883 - val_gender_output_acc: 0.6714 - val_image_quality_output_acc: 0.7035 - val_age_output_acc: 0.7999 - val_weight_output_acc: 0.8168 - val_bag_output_acc: 0.7204 - val_footwear_output_acc: 0.7328 - val_pose_output_acc: 0.7520 - val_emotion_output_acc: 0.8521\n",
            "Epoch 11/200\n",
            "Epoch 11/200\n",
            "360/360 [==============================] - 150s 417ms/step - loss: 0.4068 - gender_output_loss: 0.6134 - image_quality_output_loss: 0.5742 - age_output_loss: 0.4532 - weight_output_loss: 0.4194 - bag_output_loss: 0.5318 - footwear_output_loss: 0.5549 - pose_output_loss: 0.5365 - emotion_output_loss: 0.3841 - gender_output_acc: 0.6545 - image_quality_output_acc: 0.7021 - age_output_acc: 0.7996 - weight_output_acc: 0.8171 - bag_output_acc: 0.7249 - footwear_output_acc: 0.7137 - pose_output_acc: 0.7453 - emotion_output_acc: 0.8569 - val_loss: 0.3996 - val_gender_output_loss: 0.5861 - val_image_quality_output_loss: 0.5748 - val_age_output_loss: 0.4493 - val_weight_output_loss: 0.4158 - val_bag_output_loss: 0.5329 - val_footwear_output_loss: 0.5252 - val_pose_output_loss: 0.5220 - val_emotion_output_loss: 0.3898 - val_gender_output_acc: 0.6887 - val_image_quality_output_acc: 0.6991 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8180 - val_bag_output_acc: 0.7161 - val_footwear_output_acc: 0.7340 - val_pose_output_acc: 0.7555 - val_emotion_output_acc: 0.8516\n",
            "360/360 [==============================] - 150s 417ms/step - loss: 0.4068 - gender_output_loss: 0.6134 - image_quality_output_loss: 0.5742 - age_output_loss: 0.4532 - weight_output_loss: 0.4194 - bag_output_loss: 0.5318 - footwear_output_loss: 0.5549 - pose_output_loss: 0.5365 - emotion_output_loss: 0.3841 - gender_output_acc: 0.6545 - image_quality_output_acc: 0.7021 - age_output_acc: 0.7996 - weight_output_acc: 0.8171 - bag_output_acc: 0.7249 - footwear_output_acc: 0.7137 - pose_output_acc: 0.7453 - emotion_output_acc: 0.8569 - val_loss: 0.3996 - val_gender_output_loss: 0.5861 - val_image_quality_output_loss: 0.5748 - val_age_output_loss: 0.4493 - val_weight_output_loss: 0.4158 - val_bag_output_loss: 0.5329 - val_footwear_output_loss: 0.5252 - val_pose_output_loss: 0.5220 - val_emotion_output_loss: 0.3898 - val_gender_output_acc: 0.6887 - val_image_quality_output_acc: 0.6991 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8180 - val_bag_output_acc: 0.7161 - val_footwear_output_acc: 0.7340 - val_pose_output_acc: 0.7555 - val_emotion_output_acc: 0.8516\n",
            "Epoch 12/200\n",
            "Epoch 12/200\n",
            "360/360 [==============================] - 148s 412ms/step - loss: 0.4055 - gender_output_loss: 0.6090 - image_quality_output_loss: 0.5742 - age_output_loss: 0.4534 - weight_output_loss: 0.4186 - bag_output_loss: 0.5306 - footwear_output_loss: 0.5497 - pose_output_loss: 0.5357 - emotion_output_loss: 0.3839 - gender_output_acc: 0.6628 - image_quality_output_acc: 0.7016 - age_output_acc: 0.7999 - weight_output_acc: 0.8169 - bag_output_acc: 0.7264 - footwear_output_acc: 0.7184 - pose_output_acc: 0.7465 - emotion_output_acc: 0.8565 - val_loss: 0.4023 - val_gender_output_loss: 0.6005 - val_image_quality_output_loss: 0.5763 - val_age_output_loss: 0.4501 - val_weight_output_loss: 0.4202 - val_bag_output_loss: 0.5312 - val_footwear_output_loss: 0.5269 - val_pose_output_loss: 0.5250 - val_emotion_output_loss: 0.3926 - val_gender_output_acc: 0.6706 - val_image_quality_output_acc: 0.6973 - val_age_output_acc: 0.7999 - val_weight_output_acc: 0.8144 - val_bag_output_acc: 0.7249 - val_footwear_output_acc: 0.7373 - val_pose_output_acc: 0.7553 - val_emotion_output_acc: 0.8522\n",
            "360/360 [==============================] - 148s 412ms/step - loss: 0.4055 - gender_output_loss: 0.6090 - image_quality_output_loss: 0.5742 - age_output_loss: 0.4534 - weight_output_loss: 0.4186 - bag_output_loss: 0.5306 - footwear_output_loss: 0.5497 - pose_output_loss: 0.5357 - emotion_output_loss: 0.3839 - gender_output_acc: 0.6628 - image_quality_output_acc: 0.7016 - age_output_acc: 0.7999 - weight_output_acc: 0.8169 - bag_output_acc: 0.7264 - footwear_output_acc: 0.7184 - pose_output_acc: 0.7465 - emotion_output_acc: 0.8565 - val_loss: 0.4023 - val_gender_output_loss: 0.6005 - val_image_quality_output_loss: 0.5763 - val_age_output_loss: 0.4501 - val_weight_output_loss: 0.4202 - val_bag_output_loss: 0.5312 - val_footwear_output_loss: 0.5269 - val_pose_output_loss: 0.5250 - val_emotion_output_loss: 0.3926 - val_gender_output_acc: 0.6706 - val_image_quality_output_acc: 0.6973 - val_age_output_acc: 0.7999 - val_weight_output_acc: 0.8144 - val_bag_output_acc: 0.7249 - val_footwear_output_acc: 0.7373 - val_pose_output_acc: 0.7553 - val_emotion_output_acc: 0.8522\n",
            "Epoch 13/200\n",
            "Epoch 13/200\n",
            "360/360 [==============================] - 149s 413ms/step - loss: 0.4043 - gender_output_loss: 0.6028 - image_quality_output_loss: 0.5742 - age_output_loss: 0.4526 - weight_output_loss: 0.4188 - bag_output_loss: 0.5292 - footwear_output_loss: 0.5480 - pose_output_loss: 0.5335 - emotion_output_loss: 0.3839 - gender_output_acc: 0.6714 - image_quality_output_acc: 0.7014 - age_output_acc: 0.7996 - weight_output_acc: 0.8170 - bag_output_acc: 0.7270 - footwear_output_acc: 0.7202 - pose_output_acc: 0.7461 - emotion_output_acc: 0.8567 - val_loss: 0.4104 - val_gender_output_loss: 0.6239 - val_image_quality_output_loss: 0.5759 - val_age_output_loss: 0.4567 - val_weight_output_loss: 0.4239 - val_bag_output_loss: 0.5525 - val_footwear_output_loss: 0.5235 - val_pose_output_loss: 0.5483 - val_emotion_output_loss: 0.3991 - val_gender_output_acc: 0.6642 - val_image_quality_output_acc: 0.6986 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8181 - val_bag_output_acc: 0.7126 - val_footwear_output_acc: 0.7439 - val_pose_output_acc: 0.7490 - val_emotion_output_acc: 0.8522\n",
            "360/360 [==============================] - 149s 413ms/step - loss: 0.4043 - gender_output_loss: 0.6028 - image_quality_output_loss: 0.5742 - age_output_loss: 0.4526 - weight_output_loss: 0.4188 - bag_output_loss: 0.5292 - footwear_output_loss: 0.5480 - pose_output_loss: 0.5335 - emotion_output_loss: 0.3839 - gender_output_acc: 0.6714 - image_quality_output_acc: 0.7014 - age_output_acc: 0.7996 - weight_output_acc: 0.8170 - bag_output_acc: 0.7270 - footwear_output_acc: 0.7202 - pose_output_acc: 0.7461 - emotion_output_acc: 0.8567 - val_loss: 0.4104 - val_gender_output_loss: 0.6239 - val_image_quality_output_loss: 0.5759 - val_age_output_loss: 0.4567 - val_weight_output_loss: 0.4239 - val_bag_output_loss: 0.5525 - val_footwear_output_loss: 0.5235 - val_pose_output_loss: 0.5483 - val_emotion_output_loss: 0.3991 - val_gender_output_acc: 0.6642 - val_image_quality_output_acc: 0.6986 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8181 - val_bag_output_acc: 0.7126 - val_footwear_output_acc: 0.7439 - val_pose_output_acc: 0.7490 - val_emotion_output_acc: 0.8522\n",
            "Epoch 14/200\n",
            "Epoch 14/200\n",
            "360/360 [==============================] - 149s 415ms/step - loss: 0.4037 - gender_output_loss: 0.6017 - image_quality_output_loss: 0.5739 - age_output_loss: 0.4525 - weight_output_loss: 0.4187 - bag_output_loss: 0.5298 - footwear_output_loss: 0.5437 - pose_output_loss: 0.5325 - emotion_output_loss: 0.3846 - gender_output_acc: 0.6722 - image_quality_output_acc: 0.7017 - age_output_acc: 0.8000 - weight_output_acc: 0.8170 - bag_output_acc: 0.7246 - footwear_output_acc: 0.7202 - pose_output_acc: 0.7461 - emotion_output_acc: 0.8566 - val_loss: 0.4008 - val_gender_output_loss: 0.5838 - val_image_quality_output_loss: 0.5756 - val_age_output_loss: 0.4533 - val_weight_output_loss: 0.4229 - val_bag_output_loss: 0.5320 - val_footwear_output_loss: 0.5220 - val_pose_output_loss: 0.5296 - val_emotion_output_loss: 0.3891 - val_gender_output_acc: 0.6880 - val_image_quality_output_acc: 0.6969 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8181 - val_bag_output_acc: 0.7207 - val_footwear_output_acc: 0.7427 - val_pose_output_acc: 0.7571 - val_emotion_output_acc: 0.8522\n",
            "360/360 [==============================] - 149s 415ms/step - loss: 0.4037 - gender_output_loss: 0.6017 - image_quality_output_loss: 0.5739 - age_output_loss: 0.4525 - weight_output_loss: 0.4187 - bag_output_loss: 0.5298 - footwear_output_loss: 0.5437 - pose_output_loss: 0.5325 - emotion_output_loss: 0.3846 - gender_output_acc: 0.6722 - image_quality_output_acc: 0.7017 - age_output_acc: 0.8000 - weight_output_acc: 0.8170 - bag_output_acc: 0.7246 - footwear_output_acc: 0.7202 - pose_output_acc: 0.7461 - emotion_output_acc: 0.8566 - val_loss: 0.4008 - val_gender_output_loss: 0.5838 - val_image_quality_output_loss: 0.5756 - val_age_output_loss: 0.4533 - val_weight_output_loss: 0.4229 - val_bag_output_loss: 0.5320 - val_footwear_output_loss: 0.5220 - val_pose_output_loss: 0.5296 - val_emotion_output_loss: 0.3891 - val_gender_output_acc: 0.6880 - val_image_quality_output_acc: 0.6969 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8181 - val_bag_output_acc: 0.7207 - val_footwear_output_acc: 0.7427 - val_pose_output_acc: 0.7571 - val_emotion_output_acc: 0.8522\n",
            "Epoch 15/200\n",
            "Epoch 15/200\n",
            "360/360 [==============================] - 148s 412ms/step - loss: 0.4017 - gender_output_loss: 0.5916 - image_quality_output_loss: 0.5725 - age_output_loss: 0.4515 - weight_output_loss: 0.4177 - bag_output_loss: 0.5277 - footwear_output_loss: 0.5422 - pose_output_loss: 0.5301 - emotion_output_loss: 0.3833 - gender_output_acc: 0.6747 - image_quality_output_acc: 0.7024 - age_output_acc: 0.8000 - weight_output_acc: 0.8178 - bag_output_acc: 0.7292 - footwear_output_acc: 0.7251 - pose_output_acc: 0.7473 - emotion_output_acc: 0.8566 - val_loss: 0.4022 - val_gender_output_loss: 0.5881 - val_image_quality_output_loss: 0.5746 - val_age_output_loss: 0.4541 - val_weight_output_loss: 0.4183 - val_bag_output_loss: 0.5418 - val_footwear_output_loss: 0.5181 - val_pose_output_loss: 0.5292 - val_emotion_output_loss: 0.3975 - val_gender_output_acc: 0.7068 - val_image_quality_output_acc: 0.6996 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8196 - val_bag_output_acc: 0.7244 - val_footwear_output_acc: 0.7432 - val_pose_output_acc: 0.7622 - val_emotion_output_acc: 0.8522\n",
            "360/360 [==============================] - 148s 412ms/step - loss: 0.4017 - gender_output_loss: 0.5916 - image_quality_output_loss: 0.5725 - age_output_loss: 0.4515 - weight_output_loss: 0.4177 - bag_output_loss: 0.5277 - footwear_output_loss: 0.5422 - pose_output_loss: 0.5301 - emotion_output_loss: 0.3833 - gender_output_acc: 0.6747 - image_quality_output_acc: 0.7024 - age_output_acc: 0.8000 - weight_output_acc: 0.8178 - bag_output_acc: 0.7292 - footwear_output_acc: 0.7251 - pose_output_acc: 0.7473 - emotion_output_acc: 0.8566 - val_loss: 0.4022 - val_gender_output_loss: 0.5881 - val_image_quality_output_loss: 0.5746 - val_age_output_loss: 0.4541 - val_weight_output_loss: 0.4183 - val_bag_output_loss: 0.5418 - val_footwear_output_loss: 0.5181 - val_pose_output_loss: 0.5292 - val_emotion_output_loss: 0.3975 - val_gender_output_acc: 0.7068 - val_image_quality_output_acc: 0.6996 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8196 - val_bag_output_acc: 0.7244 - val_footwear_output_acc: 0.7432 - val_pose_output_acc: 0.7622 - val_emotion_output_acc: 0.8522\n",
            "Epoch 16/200\n",
            "Epoch 16/200\n",
            "360/360 [==============================] - 148s 411ms/step - loss: 0.4006 - gender_output_loss: 0.5871 - image_quality_output_loss: 0.5726 - age_output_loss: 0.4514 - weight_output_loss: 0.4178 - bag_output_loss: 0.5260 - footwear_output_loss: 0.5385 - pose_output_loss: 0.5296 - emotion_output_loss: 0.3832 - gender_output_acc: 0.6815 - image_quality_output_acc: 0.7030 - age_output_acc: 0.7996 - weight_output_acc: 0.8176 - bag_output_acc: 0.7299 - footwear_output_acc: 0.7276 - pose_output_acc: 0.7477 - emotion_output_acc: 0.8567 - val_loss: 0.4175 - val_gender_output_loss: 0.7501 - val_image_quality_output_loss: 0.5768 - val_age_output_loss: 0.4548 - val_weight_output_loss: 0.4162 - val_bag_output_loss: 0.5433 - val_footwear_output_loss: 0.5204 - val_pose_output_loss: 0.5241 - val_emotion_output_loss: 0.3891 - val_gender_output_acc: 0.5709 - val_image_quality_output_acc: 0.6999 - val_age_output_acc: 0.7997 - val_weight_output_acc: 0.8187 - val_bag_output_acc: 0.7103 - val_footwear_output_acc: 0.7439 - val_pose_output_acc: 0.7536 - val_emotion_output_acc: 0.8522\n",
            "360/360 [==============================] - 148s 411ms/step - loss: 0.4006 - gender_output_loss: 0.5871 - image_quality_output_loss: 0.5726 - age_output_loss: 0.4514 - weight_output_loss: 0.4178 - bag_output_loss: 0.5260 - footwear_output_loss: 0.5385 - pose_output_loss: 0.5296 - emotion_output_loss: 0.3832 - gender_output_acc: 0.6815 - image_quality_output_acc: 0.7030 - age_output_acc: 0.7996 - weight_output_acc: 0.8176 - bag_output_acc: 0.7299 - footwear_output_acc: 0.7276 - pose_output_acc: 0.7477 - emotion_output_acc: 0.8567 - val_loss: 0.4175 - val_gender_output_loss: 0.7501 - val_image_quality_output_loss: 0.5768 - val_age_output_loss: 0.4548 - val_weight_output_loss: 0.4162 - val_bag_output_loss: 0.5433 - val_footwear_output_loss: 0.5204 - val_pose_output_loss: 0.5241 - val_emotion_output_loss: 0.3891 - val_gender_output_acc: 0.5709 - val_image_quality_output_acc: 0.6999 - val_age_output_acc: 0.7997 - val_weight_output_acc: 0.8187 - val_bag_output_acc: 0.7103 - val_footwear_output_acc: 0.7439 - val_pose_output_acc: 0.7536 - val_emotion_output_acc: 0.8522\n",
            "Epoch 17/200\n",
            "Epoch 17/200\n",
            "360/360 [==============================] - 148s 410ms/step - loss: 0.3994 - gender_output_loss: 0.5834 - image_quality_output_loss: 0.5710 - age_output_loss: 0.4511 - weight_output_loss: 0.4164 - bag_output_loss: 0.5247 - footwear_output_loss: 0.5373 - pose_output_loss: 0.5274 - emotion_output_loss: 0.3826 - gender_output_acc: 0.6862 - image_quality_output_acc: 0.7028 - age_output_acc: 0.7999 - weight_output_acc: 0.8178 - bag_output_acc: 0.7328 - footwear_output_acc: 0.7288 - pose_output_acc: 0.7476 - emotion_output_acc: 0.8566 - val_loss: 0.3913 - val_gender_output_loss: 0.5579 - val_image_quality_output_loss: 0.5687 - val_age_output_loss: 0.4494 - val_weight_output_loss: 0.4123 - val_bag_output_loss: 0.5218 - val_footwear_output_loss: 0.5042 - val_pose_output_loss: 0.5107 - val_emotion_output_loss: 0.3879 - val_gender_output_acc: 0.7101 - val_image_quality_output_acc: 0.7029 - val_age_output_acc: 0.8004 - val_weight_output_acc: 0.8191 - val_bag_output_acc: 0.7374 - val_footwear_output_acc: 0.7498 - val_pose_output_acc: 0.7573 - val_emotion_output_acc: 0.8522\n",
            "360/360 [==============================] - 148s 410ms/step - loss: 0.3994 - gender_output_loss: 0.5834 - image_quality_output_loss: 0.5710 - age_output_loss: 0.4511 - weight_output_loss: 0.4164 - bag_output_loss: 0.5247 - footwear_output_loss: 0.5373 - pose_output_loss: 0.5274 - emotion_output_loss: 0.3826 - gender_output_acc: 0.6862 - image_quality_output_acc: 0.7028 - age_output_acc: 0.7999 - weight_output_acc: 0.8178 - bag_output_acc: 0.7328 - footwear_output_acc: 0.7288 - pose_output_acc: 0.7476 - emotion_output_acc: 0.8566 - val_loss: 0.3913 - val_gender_output_loss: 0.5579 - val_image_quality_output_loss: 0.5687 - val_age_output_loss: 0.4494 - val_weight_output_loss: 0.4123 - val_bag_output_loss: 0.5218 - val_footwear_output_loss: 0.5042 - val_pose_output_loss: 0.5107 - val_emotion_output_loss: 0.3879 - val_gender_output_acc: 0.7101 - val_image_quality_output_acc: 0.7029 - val_age_output_acc: 0.8004 - val_weight_output_acc: 0.8191 - val_bag_output_acc: 0.7374 - val_footwear_output_acc: 0.7498 - val_pose_output_acc: 0.7573 - val_emotion_output_acc: 0.8522\n",
            "Epoch 18/200\n",
            "Epoch 18/200\n",
            "360/360 [==============================] - 146s 407ms/step - loss: 0.3983 - gender_output_loss: 0.5798 - image_quality_output_loss: 0.5712 - age_output_loss: 0.4508 - weight_output_loss: 0.4167 - bag_output_loss: 0.5254 - footwear_output_loss: 0.5344 - pose_output_loss: 0.5219 - emotion_output_loss: 0.3828 - gender_output_acc: 0.6878 - image_quality_output_acc: 0.7019 - age_output_acc: 0.8001 - weight_output_acc: 0.8171 - bag_output_acc: 0.7320 - footwear_output_acc: 0.7299 - pose_output_acc: 0.7516 - emotion_output_acc: 0.8565 - val_loss: 0.3995 - val_gender_output_loss: 0.6023 - val_image_quality_output_loss: 0.5727 - val_age_output_loss: 0.4499 - val_weight_output_loss: 0.4141 - val_bag_output_loss: 0.5261 - val_footwear_output_loss: 0.5289 - val_pose_output_loss: 0.5126 - val_emotion_output_loss: 0.3888 - val_gender_output_acc: 0.6625 - val_image_quality_output_acc: 0.7004 - val_age_output_acc: 0.7990 - val_weight_output_acc: 0.8191 - val_bag_output_acc: 0.7292 - val_footwear_output_acc: 0.7366 - val_pose_output_acc: 0.7614 - val_emotion_output_acc: 0.8519\n",
            "360/360 [==============================] - 146s 407ms/step - loss: 0.3983 - gender_output_loss: 0.5798 - image_quality_output_loss: 0.5712 - age_output_loss: 0.4508 - weight_output_loss: 0.4167 - bag_output_loss: 0.5254 - footwear_output_loss: 0.5344 - pose_output_loss: 0.5219 - emotion_output_loss: 0.3828 - gender_output_acc: 0.6878 - image_quality_output_acc: 0.7019 - age_output_acc: 0.8001 - weight_output_acc: 0.8171 - bag_output_acc: 0.7320 - footwear_output_acc: 0.7299 - pose_output_acc: 0.7516 - emotion_output_acc: 0.8565 - val_loss: 0.3995 - val_gender_output_loss: 0.6023 - val_image_quality_output_loss: 0.5727 - val_age_output_loss: 0.4499 - val_weight_output_loss: 0.4141 - val_bag_output_loss: 0.5261 - val_footwear_output_loss: 0.5289 - val_pose_output_loss: 0.5126 - val_emotion_output_loss: 0.3888 - val_gender_output_acc: 0.6625 - val_image_quality_output_acc: 0.7004 - val_age_output_acc: 0.7990 - val_weight_output_acc: 0.8191 - val_bag_output_acc: 0.7292 - val_footwear_output_acc: 0.7366 - val_pose_output_acc: 0.7614 - val_emotion_output_acc: 0.8519\n",
            "Epoch 19/200\n",
            "Epoch 19/200\n",
            "360/360 [==============================] - 147s 409ms/step - loss: 0.3969 - gender_output_loss: 0.5705 - image_quality_output_loss: 0.5714 - age_output_loss: 0.4505 - weight_output_loss: 0.4173 - bag_output_loss: 0.5231 - footwear_output_loss: 0.5323 - pose_output_loss: 0.5215 - emotion_output_loss: 0.3822 - gender_output_acc: 0.6990 - image_quality_output_acc: 0.7025 - age_output_acc: 0.7999 - weight_output_acc: 0.8178 - bag_output_acc: 0.7324 - footwear_output_acc: 0.7310 - pose_output_acc: 0.7518 - emotion_output_acc: 0.8566 - val_loss: 0.4241 - val_gender_output_loss: 0.6553 - val_image_quality_output_loss: 0.5743 - val_age_output_loss: 0.4637 - val_weight_output_loss: 0.4259 - val_bag_output_loss: 0.5959 - val_footwear_output_loss: 0.5543 - val_pose_output_loss: 0.5542 - val_emotion_output_loss: 0.4176 - val_gender_output_acc: 0.7059 - val_image_quality_output_acc: 0.6987 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8189 - val_bag_output_acc: 0.7174 - val_footwear_output_acc: 0.7391 - val_pose_output_acc: 0.7264 - val_emotion_output_acc: 0.8522\n",
            "360/360 [==============================] - 147s 409ms/step - loss: 0.3969 - gender_output_loss: 0.5705 - image_quality_output_loss: 0.5714 - age_output_loss: 0.4505 - weight_output_loss: 0.4173 - bag_output_loss: 0.5231 - footwear_output_loss: 0.5323 - pose_output_loss: 0.5215 - emotion_output_loss: 0.3822 - gender_output_acc: 0.6990 - image_quality_output_acc: 0.7025 - age_output_acc: 0.7999 - weight_output_acc: 0.8178 - bag_output_acc: 0.7324 - footwear_output_acc: 0.7310 - pose_output_acc: 0.7518 - emotion_output_acc: 0.8566 - val_loss: 0.4241 - val_gender_output_loss: 0.6553 - val_image_quality_output_loss: 0.5743 - val_age_output_loss: 0.4637 - val_weight_output_loss: 0.4259 - val_bag_output_loss: 0.5959 - val_footwear_output_loss: 0.5543 - val_pose_output_loss: 0.5542 - val_emotion_output_loss: 0.4176 - val_gender_output_acc: 0.7059 - val_image_quality_output_acc: 0.6987 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8189 - val_bag_output_acc: 0.7174 - val_footwear_output_acc: 0.7391 - val_pose_output_acc: 0.7264 - val_emotion_output_acc: 0.8522\n",
            "Epoch 20/200\n",
            "Epoch 20/200\n",
            "360/360 [==============================] - 148s 410ms/step - loss: 0.3953 - gender_output_loss: 0.5665 - image_quality_output_loss: 0.5708 - age_output_loss: 0.4506 - weight_output_loss: 0.4175 - bag_output_loss: 0.5227 - footwear_output_loss: 0.5297 - pose_output_loss: 0.5145 - emotion_output_loss: 0.3811 - gender_output_acc: 0.7030 - image_quality_output_acc: 0.7030 - age_output_acc: 0.7995 - weight_output_acc: 0.8164 - bag_output_acc: 0.7341 - footwear_output_acc: 0.7307 - pose_output_acc: 0.7554 - emotion_output_acc: 0.8564 - val_loss: 0.3960 - val_gender_output_loss: 0.6042 - val_image_quality_output_loss: 0.5676 - val_age_output_loss: 0.4490 - val_weight_output_loss: 0.4139 - val_bag_output_loss: 0.5291 - val_footwear_output_loss: 0.5066 - val_pose_output_loss: 0.5022 - val_emotion_output_loss: 0.3870 - val_gender_output_acc: 0.6719 - val_image_quality_output_acc: 0.7012 - val_age_output_acc: 0.7997 - val_weight_output_acc: 0.8171 - val_bag_output_acc: 0.7179 - val_footwear_output_acc: 0.7526 - val_pose_output_acc: 0.7629 - val_emotion_output_acc: 0.8522\n",
            "360/360 [==============================] - 148s 410ms/step - loss: 0.3953 - gender_output_loss: 0.5665 - image_quality_output_loss: 0.5708 - age_output_loss: 0.4506 - weight_output_loss: 0.4175 - bag_output_loss: 0.5227 - footwear_output_loss: 0.5297 - pose_output_loss: 0.5145 - emotion_output_loss: 0.3811 - gender_output_acc: 0.7030 - image_quality_output_acc: 0.7030 - age_output_acc: 0.7995 - weight_output_acc: 0.8164 - bag_output_acc: 0.7341 - footwear_output_acc: 0.7307 - pose_output_acc: 0.7554 - emotion_output_acc: 0.8564 - val_loss: 0.3960 - val_gender_output_loss: 0.6042 - val_image_quality_output_loss: 0.5676 - val_age_output_loss: 0.4490 - val_weight_output_loss: 0.4139 - val_bag_output_loss: 0.5291 - val_footwear_output_loss: 0.5066 - val_pose_output_loss: 0.5022 - val_emotion_output_loss: 0.3870 - val_gender_output_acc: 0.6719 - val_image_quality_output_acc: 0.7012 - val_age_output_acc: 0.7997 - val_weight_output_acc: 0.8171 - val_bag_output_acc: 0.7179 - val_footwear_output_acc: 0.7526 - val_pose_output_acc: 0.7629 - val_emotion_output_acc: 0.8522\n",
            "Epoch 21/200\n",
            "Epoch 21/200\n",
            "360/360 [==============================] - 147s 409ms/step - loss: 0.3940 - gender_output_loss: 0.5573 - image_quality_output_loss: 0.5706 - age_output_loss: 0.4506 - weight_output_loss: 0.4176 - bag_output_loss: 0.5231 - footwear_output_loss: 0.5303 - pose_output_loss: 0.5092 - emotion_output_loss: 0.3812 - gender_output_acc: 0.7108 - image_quality_output_acc: 0.7027 - age_output_acc: 0.7998 - weight_output_acc: 0.8169 - bag_output_acc: 0.7323 - footwear_output_acc: 0.7343 - pose_output_acc: 0.7575 - emotion_output_acc: 0.8568 - val_loss: 0.5004 - val_gender_output_loss: 0.8898 - val_image_quality_output_loss: 0.6033 - val_age_output_loss: 0.5157 - val_weight_output_loss: 0.4491 - val_bag_output_loss: 0.6572 - val_footwear_output_loss: 0.7963 - val_pose_output_loss: 0.6485 - val_emotion_output_loss: 0.4437 - val_gender_output_acc: 0.6438 - val_image_quality_output_acc: 0.6986 - val_age_output_acc: 0.7932 - val_weight_output_acc: 0.8123 - val_bag_output_acc: 0.7067 - val_footwear_output_acc: 0.7087 - val_pose_output_acc: 0.7287 - val_emotion_output_acc: 0.8522\n",
            "360/360 [==============================] - 147s 409ms/step - loss: 0.3940 - gender_output_loss: 0.5573 - image_quality_output_loss: 0.5706 - age_output_loss: 0.4506 - weight_output_loss: 0.4176 - bag_output_loss: 0.5231 - footwear_output_loss: 0.5303 - pose_output_loss: 0.5092 - emotion_output_loss: 0.3812 - gender_output_acc: 0.7108 - image_quality_output_acc: 0.7027 - age_output_acc: 0.7998 - weight_output_acc: 0.8169 - bag_output_acc: 0.7323 - footwear_output_acc: 0.7343 - pose_output_acc: 0.7575 - emotion_output_acc: 0.8568 - val_loss: 0.5004 - val_gender_output_loss: 0.8898 - val_image_quality_output_loss: 0.6033 - val_age_output_loss: 0.5157 - val_weight_output_loss: 0.4491 - val_bag_output_loss: 0.6572 - val_footwear_output_loss: 0.7963 - val_pose_output_loss: 0.6485 - val_emotion_output_loss: 0.4437 - val_gender_output_acc: 0.6438 - val_image_quality_output_acc: 0.6986 - val_age_output_acc: 0.7932 - val_weight_output_acc: 0.8123 - val_bag_output_acc: 0.7067 - val_footwear_output_acc: 0.7087 - val_pose_output_acc: 0.7287 - val_emotion_output_acc: 0.8522\n",
            "Epoch 22/200\n",
            "Epoch 22/200\n",
            "360/360 [==============================] - 147s 409ms/step - loss: 0.3923 - gender_output_loss: 0.5539 - image_quality_output_loss: 0.5685 - age_output_loss: 0.4502 - weight_output_loss: 0.4160 - bag_output_loss: 0.5230 - footwear_output_loss: 0.5268 - pose_output_loss: 0.5046 - emotion_output_loss: 0.3804 - gender_output_acc: 0.7130 - image_quality_output_acc: 0.7037 - age_output_acc: 0.7997 - weight_output_acc: 0.8177 - bag_output_acc: 0.7368 - footwear_output_acc: 0.7369 - pose_output_acc: 0.7609 - emotion_output_acc: 0.8564 - val_loss: 0.3942 - val_gender_output_loss: 0.5660 - val_image_quality_output_loss: 0.5686 - val_age_output_loss: 0.4516 - val_weight_output_loss: 0.4132 - val_bag_output_loss: 0.5335 - val_footwear_output_loss: 0.5177 - val_pose_output_loss: 0.5017 - val_emotion_output_loss: 0.3900 - val_gender_output_acc: 0.7153 - val_image_quality_output_acc: 0.7032 - val_age_output_acc: 0.8005 - val_weight_output_acc: 0.8187 - val_bag_output_acc: 0.7237 - val_footwear_output_acc: 0.7419 - val_pose_output_acc: 0.7750 - val_emotion_output_acc: 0.8522\n",
            "360/360 [==============================] - 147s 409ms/step - loss: 0.3923 - gender_output_loss: 0.5539 - image_quality_output_loss: 0.5685 - age_output_loss: 0.4502 - weight_output_loss: 0.4160 - bag_output_loss: 0.5230 - footwear_output_loss: 0.5268 - pose_output_loss: 0.5046 - emotion_output_loss: 0.3804 - gender_output_acc: 0.7130 - image_quality_output_acc: 0.7037 - age_output_acc: 0.7997 - weight_output_acc: 0.8177 - bag_output_acc: 0.7368 - footwear_output_acc: 0.7369 - pose_output_acc: 0.7609 - emotion_output_acc: 0.8564 - val_loss: 0.3942 - val_gender_output_loss: 0.5660 - val_image_quality_output_loss: 0.5686 - val_age_output_loss: 0.4516 - val_weight_output_loss: 0.4132 - val_bag_output_loss: 0.5335 - val_footwear_output_loss: 0.5177 - val_pose_output_loss: 0.5017 - val_emotion_output_loss: 0.3900 - val_gender_output_acc: 0.7153 - val_image_quality_output_acc: 0.7032 - val_age_output_acc: 0.8005 - val_weight_output_acc: 0.8187 - val_bag_output_acc: 0.7237 - val_footwear_output_acc: 0.7419 - val_pose_output_acc: 0.7750 - val_emotion_output_acc: 0.8522\n",
            "Epoch 23/200\n",
            "Epoch 23/200\n",
            "360/360 [==============================] - 149s 414ms/step - loss: 0.3898 - gender_output_loss: 0.5408 - image_quality_output_loss: 0.5686 - age_output_loss: 0.4502 - weight_output_loss: 0.4166 - bag_output_loss: 0.5210 - footwear_output_loss: 0.5267 - pose_output_loss: 0.4945 - emotion_output_loss: 0.3799 - gender_output_acc: 0.7228 - image_quality_output_acc: 0.7029 - age_output_acc: 0.7999 - weight_output_acc: 0.8167 - bag_output_acc: 0.7360 - footwear_output_acc: 0.7367 - pose_output_acc: 0.7671 - emotion_output_acc: 0.8565 - val_loss: 0.3889 - val_gender_output_loss: 0.5150 - val_image_quality_output_loss: 0.5650 - val_age_output_loss: 0.4465 - val_weight_output_loss: 0.4120 - val_bag_output_loss: 0.5264 - val_footwear_output_loss: 0.5033 - val_pose_output_loss: 0.5273 - val_emotion_output_loss: 0.3931 - val_gender_output_acc: 0.7450 - val_image_quality_output_acc: 0.7065 - val_age_output_acc: 0.8011 - val_weight_output_acc: 0.8197 - val_bag_output_acc: 0.7252 - val_footwear_output_acc: 0.7535 - val_pose_output_acc: 0.7399 - val_emotion_output_acc: 0.8522\n",
            "360/360 [==============================] - 149s 414ms/step - loss: 0.3898 - gender_output_loss: 0.5408 - image_quality_output_loss: 0.5686 - age_output_loss: 0.4502 - weight_output_loss: 0.4166 - bag_output_loss: 0.5210 - footwear_output_loss: 0.5267 - pose_output_loss: 0.4945 - emotion_output_loss: 0.3799 - gender_output_acc: 0.7228 - image_quality_output_acc: 0.7029 - age_output_acc: 0.7999 - weight_output_acc: 0.8167 - bag_output_acc: 0.7360 - footwear_output_acc: 0.7367 - pose_output_acc: 0.7671 - emotion_output_acc: 0.8565 - val_loss: 0.3889 - val_gender_output_loss: 0.5150 - val_image_quality_output_loss: 0.5650 - val_age_output_loss: 0.4465 - val_weight_output_loss: 0.4120 - val_bag_output_loss: 0.5264 - val_footwear_output_loss: 0.5033 - val_pose_output_loss: 0.5273 - val_emotion_output_loss: 0.3931 - val_gender_output_acc: 0.7450 - val_image_quality_output_acc: 0.7065 - val_age_output_acc: 0.8011 - val_weight_output_acc: 0.8197 - val_bag_output_acc: 0.7252 - val_footwear_output_acc: 0.7535 - val_pose_output_acc: 0.7399 - val_emotion_output_acc: 0.8522\n",
            "Epoch 24/200\n",
            "Epoch 24/200\n",
            "360/360 [==============================] - 149s 415ms/step - loss: 0.3876 - gender_output_loss: 0.5333 - image_quality_output_loss: 0.5672 - age_output_loss: 0.4497 - weight_output_loss: 0.4158 - bag_output_loss: 0.5205 - footwear_output_loss: 0.5240 - pose_output_loss: 0.4861 - emotion_output_loss: 0.3792 - gender_output_acc: 0.7258 - image_quality_output_acc: 0.7032 - age_output_acc: 0.7993 - weight_output_acc: 0.8183 - bag_output_acc: 0.7358 - footwear_output_acc: 0.7391 - pose_output_acc: 0.7731 - emotion_output_acc: 0.8565 - val_loss: 0.3887 - val_gender_output_loss: 0.5708 - val_image_quality_output_loss: 0.5663 - val_age_output_loss: 0.4528 - val_weight_output_loss: 0.4152 - val_bag_output_loss: 0.5324 - val_footwear_output_loss: 0.4959 - val_pose_output_loss: 0.4635 - val_emotion_output_loss: 0.3904 - val_gender_output_acc: 0.7376 - val_image_quality_output_acc: 0.7047 - val_age_output_acc: 0.8009 - val_weight_output_acc: 0.8191 - val_bag_output_acc: 0.7318 - val_footwear_output_acc: 0.7560 - val_pose_output_acc: 0.7917 - val_emotion_output_acc: 0.8522\n",
            "360/360 [==============================] - 149s 415ms/step - loss: 0.3876 - gender_output_loss: 0.5333 - image_quality_output_loss: 0.5672 - age_output_loss: 0.4497 - weight_output_loss: 0.4158 - bag_output_loss: 0.5205 - footwear_output_loss: 0.5240 - pose_output_loss: 0.4861 - emotion_output_loss: 0.3792 - gender_output_acc: 0.7258 - image_quality_output_acc: 0.7032 - age_output_acc: 0.7993 - weight_output_acc: 0.8183 - bag_output_acc: 0.7358 - footwear_output_acc: 0.7391 - pose_output_acc: 0.7731 - emotion_output_acc: 0.8565 - val_loss: 0.3887 - val_gender_output_loss: 0.5708 - val_image_quality_output_loss: 0.5663 - val_age_output_loss: 0.4528 - val_weight_output_loss: 0.4152 - val_bag_output_loss: 0.5324 - val_footwear_output_loss: 0.4959 - val_pose_output_loss: 0.4635 - val_emotion_output_loss: 0.3904 - val_gender_output_acc: 0.7376 - val_image_quality_output_acc: 0.7047 - val_age_output_acc: 0.8009 - val_weight_output_acc: 0.8191 - val_bag_output_acc: 0.7318 - val_footwear_output_acc: 0.7560 - val_pose_output_acc: 0.7917 - val_emotion_output_acc: 0.8522\n",
            "Epoch 25/200\n",
            "Epoch 25/200\n",
            "360/360 [==============================] - 147s 407ms/step - loss: 0.3857 - gender_output_loss: 0.5276 - image_quality_output_loss: 0.5670 - age_output_loss: 0.4496 - weight_output_loss: 0.4162 - bag_output_loss: 0.5188 - footwear_output_loss: 0.5233 - pose_output_loss: 0.4768 - emotion_output_loss: 0.3775 - gender_output_acc: 0.7308 - image_quality_output_acc: 0.7034 - age_output_acc: 0.7994 - weight_output_acc: 0.8179 - bag_output_acc: 0.7368 - footwear_output_acc: 0.7374 - pose_output_acc: 0.7769 - emotion_output_acc: 0.8566 - val_loss: 0.3795 - val_gender_output_loss: 0.5120 - val_image_quality_output_loss: 0.5640 - val_age_output_loss: 0.4474 - val_weight_output_loss: 0.4174 - val_bag_output_loss: 0.5209 - val_footwear_output_loss: 0.4981 - val_pose_output_loss: 0.4532 - val_emotion_output_loss: 0.3824 - val_gender_output_acc: 0.7542 - val_image_quality_output_acc: 0.7034 - val_age_output_acc: 0.8008 - val_weight_output_acc: 0.8186 - val_bag_output_acc: 0.7265 - val_footwear_output_acc: 0.7563 - val_pose_output_acc: 0.7930 - val_emotion_output_acc: 0.8521\n",
            "360/360 [==============================] - 147s 407ms/step - loss: 0.3857 - gender_output_loss: 0.5276 - image_quality_output_loss: 0.5670 - age_output_loss: 0.4496 - weight_output_loss: 0.4162 - bag_output_loss: 0.5188 - footwear_output_loss: 0.5233 - pose_output_loss: 0.4768 - emotion_output_loss: 0.3775 - gender_output_acc: 0.7308 - image_quality_output_acc: 0.7034 - age_output_acc: 0.7994 - weight_output_acc: 0.8179 - bag_output_acc: 0.7368 - footwear_output_acc: 0.7374 - pose_output_acc: 0.7769 - emotion_output_acc: 0.8566 - val_loss: 0.3795 - val_gender_output_loss: 0.5120 - val_image_quality_output_loss: 0.5640 - val_age_output_loss: 0.4474 - val_weight_output_loss: 0.4174 - val_bag_output_loss: 0.5209 - val_footwear_output_loss: 0.4981 - val_pose_output_loss: 0.4532 - val_emotion_output_loss: 0.3824 - val_gender_output_acc: 0.7542 - val_image_quality_output_acc: 0.7034 - val_age_output_acc: 0.8008 - val_weight_output_acc: 0.8186 - val_bag_output_acc: 0.7265 - val_footwear_output_acc: 0.7563 - val_pose_output_acc: 0.7930 - val_emotion_output_acc: 0.8521\n",
            "Epoch 26/200\n",
            "Epoch 26/200\n",
            "360/360 [==============================] - 146s 407ms/step - loss: 0.3842 - gender_output_loss: 0.5196 - image_quality_output_loss: 0.5650 - age_output_loss: 0.4492 - weight_output_loss: 0.4162 - bag_output_loss: 0.5208 - footwear_output_loss: 0.5218 - pose_output_loss: 0.4721 - emotion_output_loss: 0.3772 - gender_output_acc: 0.7389 - image_quality_output_acc: 0.7034 - age_output_acc: 0.7996 - weight_output_acc: 0.8179 - bag_output_acc: 0.7354 - footwear_output_acc: 0.7420 - pose_output_acc: 0.7788 - emotion_output_acc: 0.8563 - val_loss: 0.3785 - val_gender_output_loss: 0.5208 - val_image_quality_output_loss: 0.5581 - val_age_output_loss: 0.4466 - val_weight_output_loss: 0.4139 - val_bag_output_loss: 0.5202 - val_footwear_output_loss: 0.4973 - val_pose_output_loss: 0.4425 - val_emotion_output_loss: 0.3859 - val_gender_output_acc: 0.7458 - val_image_quality_output_acc: 0.7025 - val_age_output_acc: 0.8027 - val_weight_output_acc: 0.8183 - val_bag_output_acc: 0.7321 - val_footwear_output_acc: 0.7560 - val_pose_output_acc: 0.7991 - val_emotion_output_acc: 0.8521\n",
            "360/360 [==============================] - 146s 407ms/step - loss: 0.3842 - gender_output_loss: 0.5196 - image_quality_output_loss: 0.5650 - age_output_loss: 0.4492 - weight_output_loss: 0.4162 - bag_output_loss: 0.5208 - footwear_output_loss: 0.5218 - pose_output_loss: 0.4721 - emotion_output_loss: 0.3772 - gender_output_acc: 0.7389 - image_quality_output_acc: 0.7034 - age_output_acc: 0.7996 - weight_output_acc: 0.8179 - bag_output_acc: 0.7354 - footwear_output_acc: 0.7420 - pose_output_acc: 0.7788 - emotion_output_acc: 0.8563 - val_loss: 0.3785 - val_gender_output_loss: 0.5208 - val_image_quality_output_loss: 0.5581 - val_age_output_loss: 0.4466 - val_weight_output_loss: 0.4139 - val_bag_output_loss: 0.5202 - val_footwear_output_loss: 0.4973 - val_pose_output_loss: 0.4425 - val_emotion_output_loss: 0.3859 - val_gender_output_acc: 0.7458 - val_image_quality_output_acc: 0.7025 - val_age_output_acc: 0.8027 - val_weight_output_acc: 0.8183 - val_bag_output_acc: 0.7321 - val_footwear_output_acc: 0.7560 - val_pose_output_acc: 0.7991 - val_emotion_output_acc: 0.8521\n",
            "Epoch 27/200\n",
            "Epoch 27/200\n",
            "360/360 [==============================] - 146s 407ms/step - loss: 0.3824 - gender_output_loss: 0.5106 - image_quality_output_loss: 0.5643 - age_output_loss: 0.4494 - weight_output_loss: 0.4169 - bag_output_loss: 0.5201 - footwear_output_loss: 0.5204 - pose_output_loss: 0.4656 - emotion_output_loss: 0.3768 - gender_output_acc: 0.7428 - image_quality_output_acc: 0.7043 - age_output_acc: 0.7991 - weight_output_acc: 0.8185 - bag_output_acc: 0.7372 - footwear_output_acc: 0.7418 - pose_output_acc: 0.7850 - emotion_output_acc: 0.8565 - val_loss: 0.3757 - val_gender_output_loss: 0.4866 - val_image_quality_output_loss: 0.5618 - val_age_output_loss: 0.4472 - val_weight_output_loss: 0.4137 - val_bag_output_loss: 0.5143 - val_footwear_output_loss: 0.4957 - val_pose_output_loss: 0.4528 - val_emotion_output_loss: 0.3845 - val_gender_output_acc: 0.7617 - val_image_quality_output_acc: 0.7040 - val_age_output_acc: 0.8006 - val_weight_output_acc: 0.8192 - val_bag_output_acc: 0.7397 - val_footwear_output_acc: 0.7528 - val_pose_output_acc: 0.7887 - val_emotion_output_acc: 0.8521\n",
            "360/360 [==============================] - 146s 407ms/step - loss: 0.3824 - gender_output_loss: 0.5106 - image_quality_output_loss: 0.5643 - age_output_loss: 0.4494 - weight_output_loss: 0.4169 - bag_output_loss: 0.5201 - footwear_output_loss: 0.5204 - pose_output_loss: 0.4656 - emotion_output_loss: 0.3768 - gender_output_acc: 0.7428 - image_quality_output_acc: 0.7043 - age_output_acc: 0.7991 - weight_output_acc: 0.8185 - bag_output_acc: 0.7372 - footwear_output_acc: 0.7418 - pose_output_acc: 0.7850 - emotion_output_acc: 0.8565 - val_loss: 0.3757 - val_gender_output_loss: 0.4866 - val_image_quality_output_loss: 0.5618 - val_age_output_loss: 0.4472 - val_weight_output_loss: 0.4137 - val_bag_output_loss: 0.5143 - val_footwear_output_loss: 0.4957 - val_pose_output_loss: 0.4528 - val_emotion_output_loss: 0.3845 - val_gender_output_acc: 0.7617 - val_image_quality_output_acc: 0.7040 - val_age_output_acc: 0.8006 - val_weight_output_acc: 0.8192 - val_bag_output_acc: 0.7397 - val_footwear_output_acc: 0.7528 - val_pose_output_acc: 0.7887 - val_emotion_output_acc: 0.8521\n",
            "Epoch 28/200\n",
            "Epoch 28/200\n",
            "360/360 [==============================] - 147s 407ms/step - loss: 0.3806 - gender_output_loss: 0.5040 - image_quality_output_loss: 0.5635 - age_output_loss: 0.4493 - weight_output_loss: 0.4152 - bag_output_loss: 0.5187 - footwear_output_loss: 0.5206 - pose_output_loss: 0.4583 - emotion_output_loss: 0.3765 - gender_output_acc: 0.7447 - image_quality_output_acc: 0.7049 - age_output_acc: 0.8000 - weight_output_acc: 0.8172 - bag_output_acc: 0.7368 - footwear_output_acc: 0.7411 - pose_output_acc: 0.7851 - emotion_output_acc: 0.8566 - val_loss: 0.4187 - val_gender_output_loss: 0.7156 - val_image_quality_output_loss: 0.5791 - val_age_output_loss: 0.4681 - val_weight_output_loss: 0.4286 - val_bag_output_loss: 0.5637 - val_footwear_output_loss: 0.5420 - val_pose_output_loss: 0.4878 - val_emotion_output_loss: 0.4021 - val_gender_output_acc: 0.6870 - val_image_quality_output_acc: 0.6895 - val_age_output_acc: 0.8001 - val_weight_output_acc: 0.8069 - val_bag_output_acc: 0.7207 - val_footwear_output_acc: 0.7436 - val_pose_output_acc: 0.7993 - val_emotion_output_acc: 0.8476\n",
            "360/360 [==============================] - 147s 407ms/step - loss: 0.3806 - gender_output_loss: 0.5040 - image_quality_output_loss: 0.5635 - age_output_loss: 0.4493 - weight_output_loss: 0.4152 - bag_output_loss: 0.5187 - footwear_output_loss: 0.5206 - pose_output_loss: 0.4583 - emotion_output_loss: 0.3765 - gender_output_acc: 0.7447 - image_quality_output_acc: 0.7049 - age_output_acc: 0.8000 - weight_output_acc: 0.8172 - bag_output_acc: 0.7368 - footwear_output_acc: 0.7411 - pose_output_acc: 0.7851 - emotion_output_acc: 0.8566 - val_loss: 0.4187 - val_gender_output_loss: 0.7156 - val_image_quality_output_loss: 0.5791 - val_age_output_loss: 0.4681 - val_weight_output_loss: 0.4286 - val_bag_output_loss: 0.5637 - val_footwear_output_loss: 0.5420 - val_pose_output_loss: 0.4878 - val_emotion_output_loss: 0.4021 - val_gender_output_acc: 0.6870 - val_image_quality_output_acc: 0.6895 - val_age_output_acc: 0.8001 - val_weight_output_acc: 0.8069 - val_bag_output_acc: 0.7207 - val_footwear_output_acc: 0.7436 - val_pose_output_acc: 0.7993 - val_emotion_output_acc: 0.8476\n",
            "Epoch 29/200\n",
            "Epoch 29/200\n",
            "360/360 [==============================] - 147s 408ms/step - loss: 0.3797 - gender_output_loss: 0.5031 - image_quality_output_loss: 0.5638 - age_output_loss: 0.4494 - weight_output_loss: 0.4163 - bag_output_loss: 0.5171 - footwear_output_loss: 0.5191 - pose_output_loss: 0.4516 - emotion_output_loss: 0.3760 - gender_output_acc: 0.7484 - image_quality_output_acc: 0.7041 - age_output_acc: 0.7997 - weight_output_acc: 0.8178 - bag_output_acc: 0.7401 - footwear_output_acc: 0.7406 - pose_output_acc: 0.7910 - emotion_output_acc: 0.8565 - val_loss: 0.4044 - val_gender_output_loss: 0.5315 - val_image_quality_output_loss: 0.5649 - val_age_output_loss: 0.4579 - val_weight_output_loss: 0.4232 - val_bag_output_loss: 0.5316 - val_footwear_output_loss: 0.5126 - val_pose_output_loss: 0.6035 - val_emotion_output_loss: 0.4188 - val_gender_output_acc: 0.7227 - val_image_quality_output_acc: 0.6966 - val_age_output_acc: 0.7990 - val_weight_output_acc: 0.8191 - val_bag_output_acc: 0.7255 - val_footwear_output_acc: 0.7503 - val_pose_output_acc: 0.7338 - val_emotion_output_acc: 0.8519\n",
            "360/360 [==============================] - 147s 408ms/step - loss: 0.3797 - gender_output_loss: 0.5031 - image_quality_output_loss: 0.5638 - age_output_loss: 0.4494 - weight_output_loss: 0.4163 - bag_output_loss: 0.5171 - footwear_output_loss: 0.5191 - pose_output_loss: 0.4516 - emotion_output_loss: 0.3760 - gender_output_acc: 0.7484 - image_quality_output_acc: 0.7041 - age_output_acc: 0.7997 - weight_output_acc: 0.8178 - bag_output_acc: 0.7401 - footwear_output_acc: 0.7406 - pose_output_acc: 0.7910 - emotion_output_acc: 0.8565 - val_loss: 0.4044 - val_gender_output_loss: 0.5315 - val_image_quality_output_loss: 0.5649 - val_age_output_loss: 0.4579 - val_weight_output_loss: 0.4232 - val_bag_output_loss: 0.5316 - val_footwear_output_loss: 0.5126 - val_pose_output_loss: 0.6035 - val_emotion_output_loss: 0.4188 - val_gender_output_acc: 0.7227 - val_image_quality_output_acc: 0.6966 - val_age_output_acc: 0.7990 - val_weight_output_acc: 0.8191 - val_bag_output_acc: 0.7255 - val_footwear_output_acc: 0.7503 - val_pose_output_acc: 0.7338 - val_emotion_output_acc: 0.8519\n",
            "Epoch 30/200\n",
            "Epoch 30/200\n",
            "360/360 [==============================] - 150s 417ms/step - loss: 0.3771 - gender_output_loss: 0.4927 - image_quality_output_loss: 0.5622 - age_output_loss: 0.4483 - weight_output_loss: 0.4160 - bag_output_loss: 0.5159 - footwear_output_loss: 0.5152 - pose_output_loss: 0.4460 - emotion_output_loss: 0.3750 - gender_output_acc: 0.7551 - image_quality_output_acc: 0.7035 - age_output_acc: 0.7996 - weight_output_acc: 0.8172 - bag_output_acc: 0.7409 - footwear_output_acc: 0.7430 - pose_output_acc: 0.7942 - emotion_output_acc: 0.8564 - val_loss: 0.3724 - val_gender_output_loss: 0.4572 - val_image_quality_output_loss: 0.5515 - val_age_output_loss: 0.4491 - val_weight_output_loss: 0.4167 - val_bag_output_loss: 0.5217 - val_footwear_output_loss: 0.4982 - val_pose_output_loss: 0.4417 - val_emotion_output_loss: 0.3876 - val_gender_output_acc: 0.7820 - val_image_quality_output_acc: 0.7068 - val_age_output_acc: 0.8002 - val_weight_output_acc: 0.8149 - val_bag_output_acc: 0.7346 - val_footwear_output_acc: 0.7578 - val_pose_output_acc: 0.7966 - val_emotion_output_acc: 0.8522\n",
            "360/360 [==============================] - 150s 417ms/step - loss: 0.3771 - gender_output_loss: 0.4927 - image_quality_output_loss: 0.5622 - age_output_loss: 0.4483 - weight_output_loss: 0.4160 - bag_output_loss: 0.5159 - footwear_output_loss: 0.5152 - pose_output_loss: 0.4460 - emotion_output_loss: 0.3750 - gender_output_acc: 0.7551 - image_quality_output_acc: 0.7035 - age_output_acc: 0.7996 - weight_output_acc: 0.8172 - bag_output_acc: 0.7409 - footwear_output_acc: 0.7430 - pose_output_acc: 0.7942 - emotion_output_acc: 0.8564 - val_loss: 0.3724 - val_gender_output_loss: 0.4572 - val_image_quality_output_loss: 0.5515 - val_age_output_loss: 0.4491 - val_weight_output_loss: 0.4167 - val_bag_output_loss: 0.5217 - val_footwear_output_loss: 0.4982 - val_pose_output_loss: 0.4417 - val_emotion_output_loss: 0.3876 - val_gender_output_acc: 0.7820 - val_image_quality_output_acc: 0.7068 - val_age_output_acc: 0.8002 - val_weight_output_acc: 0.8149 - val_bag_output_acc: 0.7346 - val_footwear_output_acc: 0.7578 - val_pose_output_acc: 0.7966 - val_emotion_output_acc: 0.8522\n",
            "Epoch 31/200\n",
            "Epoch 31/200\n",
            "360/360 [==============================] - 154s 429ms/step - loss: 0.3748 - gender_output_loss: 0.4795 - image_quality_output_loss: 0.5602 - age_output_loss: 0.4486 - weight_output_loss: 0.4160 - bag_output_loss: 0.5146 - footwear_output_loss: 0.5131 - pose_output_loss: 0.4409 - emotion_output_loss: 0.3754 - gender_output_acc: 0.7634 - image_quality_output_acc: 0.7061 - age_output_acc: 0.7993 - weight_output_acc: 0.8180 - bag_output_acc: 0.7415 - footwear_output_acc: 0.7470 - pose_output_acc: 0.7965 - emotion_output_acc: 0.8564 - val_loss: 0.3890 - val_gender_output_loss: 0.5861 - val_image_quality_output_loss: 0.5569 - val_age_output_loss: 0.4460 - val_weight_output_loss: 0.4137 - val_bag_output_loss: 0.5138 - val_footwear_output_loss: 0.5040 - val_pose_output_loss: 0.4847 - val_emotion_output_loss: 0.3848 - val_gender_output_acc: 0.7011 - val_image_quality_output_acc: 0.7063 - val_age_output_acc: 0.8002 - val_weight_output_acc: 0.8198 - val_bag_output_acc: 0.7343 - val_footwear_output_acc: 0.7470 - val_pose_output_acc: 0.7728 - val_emotion_output_acc: 0.8518\n",
            "360/360 [==============================] - 154s 429ms/step - loss: 0.3748 - gender_output_loss: 0.4795 - image_quality_output_loss: 0.5602 - age_output_loss: 0.4486 - weight_output_loss: 0.4160 - bag_output_loss: 0.5146 - footwear_output_loss: 0.5131 - pose_output_loss: 0.4409 - emotion_output_loss: 0.3754 - gender_output_acc: 0.7634 - image_quality_output_acc: 0.7061 - age_output_acc: 0.7993 - weight_output_acc: 0.8180 - bag_output_acc: 0.7415 - footwear_output_acc: 0.7470 - pose_output_acc: 0.7965 - emotion_output_acc: 0.8564 - val_loss: 0.3890 - val_gender_output_loss: 0.5861 - val_image_quality_output_loss: 0.5569 - val_age_output_loss: 0.4460 - val_weight_output_loss: 0.4137 - val_bag_output_loss: 0.5138 - val_footwear_output_loss: 0.5040 - val_pose_output_loss: 0.4847 - val_emotion_output_loss: 0.3848 - val_gender_output_acc: 0.7011 - val_image_quality_output_acc: 0.7063 - val_age_output_acc: 0.8002 - val_weight_output_acc: 0.8198 - val_bag_output_acc: 0.7343 - val_footwear_output_acc: 0.7470 - val_pose_output_acc: 0.7728 - val_emotion_output_acc: 0.8518\n",
            "Epoch 32/200\n",
            "Epoch 32/200\n",
            "360/360 [==============================] - 153s 425ms/step - loss: 0.3739 - gender_output_loss: 0.4786 - image_quality_output_loss: 0.5589 - age_output_loss: 0.4481 - weight_output_loss: 0.4156 - bag_output_loss: 0.5155 - footwear_output_loss: 0.5128 - pose_output_loss: 0.4358 - emotion_output_loss: 0.3739 - gender_output_acc: 0.7697 - image_quality_output_acc: 0.7048 - age_output_acc: 0.7999 - weight_output_acc: 0.8178 - bag_output_acc: 0.7392 - footwear_output_acc: 0.7470 - pose_output_acc: 0.7971 - emotion_output_acc: 0.8567 - val_loss: 0.3954 - val_gender_output_loss: 0.5153 - val_image_quality_output_loss: 0.5777 - val_age_output_loss: 0.4541 - val_weight_output_loss: 0.4233 - val_bag_output_loss: 0.5374 - val_footwear_output_loss: 0.5084 - val_pose_output_loss: 0.5369 - val_emotion_output_loss: 0.4013 - val_gender_output_acc: 0.7736 - val_image_quality_output_acc: 0.6982 - val_age_output_acc: 0.7967 - val_weight_output_acc: 0.8204 - val_bag_output_acc: 0.7321 - val_footwear_output_acc: 0.7546 - val_pose_output_acc: 0.7507 - val_emotion_output_acc: 0.8521\n",
            "360/360 [==============================] - 153s 425ms/step - loss: 0.3739 - gender_output_loss: 0.4786 - image_quality_output_loss: 0.5589 - age_output_loss: 0.4481 - weight_output_loss: 0.4156 - bag_output_loss: 0.5155 - footwear_output_loss: 0.5128 - pose_output_loss: 0.4358 - emotion_output_loss: 0.3739 - gender_output_acc: 0.7697 - image_quality_output_acc: 0.7048 - age_output_acc: 0.7999 - weight_output_acc: 0.8178 - bag_output_acc: 0.7392 - footwear_output_acc: 0.7470 - pose_output_acc: 0.7971 - emotion_output_acc: 0.8567 - val_loss: 0.3954 - val_gender_output_loss: 0.5153 - val_image_quality_output_loss: 0.5777 - val_age_output_loss: 0.4541 - val_weight_output_loss: 0.4233 - val_bag_output_loss: 0.5374 - val_footwear_output_loss: 0.5084 - val_pose_output_loss: 0.5369 - val_emotion_output_loss: 0.4013 - val_gender_output_acc: 0.7736 - val_image_quality_output_acc: 0.6982 - val_age_output_acc: 0.7967 - val_weight_output_acc: 0.8204 - val_bag_output_acc: 0.7321 - val_footwear_output_acc: 0.7546 - val_pose_output_acc: 0.7507 - val_emotion_output_acc: 0.8521\n",
            "Epoch 33/200\n",
            "Epoch 33/200\n",
            "360/360 [==============================] - 151s 420ms/step - loss: 0.3713 - gender_output_loss: 0.4689 - image_quality_output_loss: 0.5587 - age_output_loss: 0.4480 - weight_output_loss: 0.4152 - bag_output_loss: 0.5131 - footwear_output_loss: 0.5119 - pose_output_loss: 0.4239 - emotion_output_loss: 0.3733 - gender_output_acc: 0.7712 - image_quality_output_acc: 0.7063 - age_output_acc: 0.7991 - weight_output_acc: 0.8179 - bag_output_acc: 0.7404 - footwear_output_acc: 0.7452 - pose_output_acc: 0.8014 - emotion_output_acc: 0.8566 - val_loss: 0.3871 - val_gender_output_loss: 0.5274 - val_image_quality_output_loss: 0.5547 - val_age_output_loss: 0.4483 - val_weight_output_loss: 0.4122 - val_bag_output_loss: 0.5174 - val_footwear_output_loss: 0.5003 - val_pose_output_loss: 0.5256 - val_emotion_output_loss: 0.3850 - val_gender_output_acc: 0.7252 - val_image_quality_output_acc: 0.7047 - val_age_output_acc: 0.7993 - val_weight_output_acc: 0.8196 - val_bag_output_acc: 0.7346 - val_footwear_output_acc: 0.7518 - val_pose_output_acc: 0.7406 - val_emotion_output_acc: 0.8514\n",
            "360/360 [==============================] - 151s 420ms/step - loss: 0.3713 - gender_output_loss: 0.4689 - image_quality_output_loss: 0.5587 - age_output_loss: 0.4480 - weight_output_loss: 0.4152 - bag_output_loss: 0.5131 - footwear_output_loss: 0.5119 - pose_output_loss: 0.4239 - emotion_output_loss: 0.3733 - gender_output_acc: 0.7712 - image_quality_output_acc: 0.7063 - age_output_acc: 0.7991 - weight_output_acc: 0.8179 - bag_output_acc: 0.7404 - footwear_output_acc: 0.7452 - pose_output_acc: 0.8014 - emotion_output_acc: 0.8566 - val_loss: 0.3871 - val_gender_output_loss: 0.5274 - val_image_quality_output_loss: 0.5547 - val_age_output_loss: 0.4483 - val_weight_output_loss: 0.4122 - val_bag_output_loss: 0.5174 - val_footwear_output_loss: 0.5003 - val_pose_output_loss: 0.5256 - val_emotion_output_loss: 0.3850 - val_gender_output_acc: 0.7252 - val_image_quality_output_acc: 0.7047 - val_age_output_acc: 0.7993 - val_weight_output_acc: 0.8196 - val_bag_output_acc: 0.7346 - val_footwear_output_acc: 0.7518 - val_pose_output_acc: 0.7406 - val_emotion_output_acc: 0.8514\n",
            "Epoch 34/200\n",
            "Epoch 34/200\n",
            "360/360 [==============================] - 148s 411ms/step - loss: 0.3707 - gender_output_loss: 0.4655 - image_quality_output_loss: 0.5579 - age_output_loss: 0.4477 - weight_output_loss: 0.4150 - bag_output_loss: 0.5131 - footwear_output_loss: 0.5115 - pose_output_loss: 0.4223 - emotion_output_loss: 0.3737 - gender_output_acc: 0.7696 - image_quality_output_acc: 0.7069 - age_output_acc: 0.7996 - weight_output_acc: 0.8174 - bag_output_acc: 0.7446 - footwear_output_acc: 0.7479 - pose_output_acc: 0.8045 - emotion_output_acc: 0.8562 - val_loss: 0.4463 - val_gender_output_loss: 0.7947 - val_image_quality_output_loss: 0.5878 - val_age_output_loss: 0.4899 - val_weight_output_loss: 0.4353 - val_bag_output_loss: 0.6109 - val_footwear_output_loss: 0.6027 - val_pose_output_loss: 0.5027 - val_emotion_output_loss: 0.4386 - val_gender_output_acc: 0.7225 - val_image_quality_output_acc: 0.6994 - val_age_output_acc: 0.8009 - val_weight_output_acc: 0.8185 - val_bag_output_acc: 0.7300 - val_footwear_output_acc: 0.7467 - val_pose_output_acc: 0.8069 - val_emotion_output_acc: 0.8519\n",
            "360/360 [==============================] - 148s 411ms/step - loss: 0.3707 - gender_output_loss: 0.4655 - image_quality_output_loss: 0.5579 - age_output_loss: 0.4477 - weight_output_loss: 0.4150 - bag_output_loss: 0.5131 - footwear_output_loss: 0.5115 - pose_output_loss: 0.4223 - emotion_output_loss: 0.3737 - gender_output_acc: 0.7696 - image_quality_output_acc: 0.7069 - age_output_acc: 0.7996 - weight_output_acc: 0.8174 - bag_output_acc: 0.7446 - footwear_output_acc: 0.7479 - pose_output_acc: 0.8045 - emotion_output_acc: 0.8562 - val_loss: 0.4463 - val_gender_output_loss: 0.7947 - val_image_quality_output_loss: 0.5878 - val_age_output_loss: 0.4899 - val_weight_output_loss: 0.4353 - val_bag_output_loss: 0.6109 - val_footwear_output_loss: 0.6027 - val_pose_output_loss: 0.5027 - val_emotion_output_loss: 0.4386 - val_gender_output_acc: 0.7225 - val_image_quality_output_acc: 0.6994 - val_age_output_acc: 0.8009 - val_weight_output_acc: 0.8185 - val_bag_output_acc: 0.7300 - val_footwear_output_acc: 0.7467 - val_pose_output_acc: 0.8069 - val_emotion_output_acc: 0.8519\n",
            "Epoch 35/200\n",
            "Epoch 35/200\n",
            "360/360 [==============================] - 147s 408ms/step - loss: 0.3688 - gender_output_loss: 0.4618 - image_quality_output_loss: 0.5547 - age_output_loss: 0.4480 - weight_output_loss: 0.4142 - bag_output_loss: 0.5112 - footwear_output_loss: 0.5104 - pose_output_loss: 0.4155 - emotion_output_loss: 0.3725 - gender_output_acc: 0.7740 - image_quality_output_acc: 0.7058 - age_output_acc: 0.7994 - weight_output_acc: 0.8176 - bag_output_acc: 0.7426 - footwear_output_acc: 0.7478 - pose_output_acc: 0.8089 - emotion_output_acc: 0.8564 - val_loss: 0.3687 - val_gender_output_loss: 0.5005 - val_image_quality_output_loss: 0.5472 - val_age_output_loss: 0.4443 - val_weight_output_loss: 0.4120 - val_bag_output_loss: 0.5194 - val_footwear_output_loss: 0.4937 - val_pose_output_loss: 0.3901 - val_emotion_output_loss: 0.3798 - val_gender_output_acc: 0.7540 - val_image_quality_output_acc: 0.7106 - val_age_output_acc: 0.7996 - val_weight_output_acc: 0.8192 - val_bag_output_acc: 0.7331 - val_footwear_output_acc: 0.7495 - val_pose_output_acc: 0.8234 - val_emotion_output_acc: 0.8512\n",
            "360/360 [==============================] - 147s 408ms/step - loss: 0.3688 - gender_output_loss: 0.4618 - image_quality_output_loss: 0.5547 - age_output_loss: 0.4480 - weight_output_loss: 0.4142 - bag_output_loss: 0.5112 - footwear_output_loss: 0.5104 - pose_output_loss: 0.4155 - emotion_output_loss: 0.3725 - gender_output_acc: 0.7740 - image_quality_output_acc: 0.7058 - age_output_acc: 0.7994 - weight_output_acc: 0.8176 - bag_output_acc: 0.7426 - footwear_output_acc: 0.7478 - pose_output_acc: 0.8089 - emotion_output_acc: 0.8564 - val_loss: 0.3687 - val_gender_output_loss: 0.5005 - val_image_quality_output_loss: 0.5472 - val_age_output_loss: 0.4443 - val_weight_output_loss: 0.4120 - val_bag_output_loss: 0.5194 - val_footwear_output_loss: 0.4937 - val_pose_output_loss: 0.3901 - val_emotion_output_loss: 0.3798 - val_gender_output_acc: 0.7540 - val_image_quality_output_acc: 0.7106 - val_age_output_acc: 0.7996 - val_weight_output_acc: 0.8192 - val_bag_output_acc: 0.7331 - val_footwear_output_acc: 0.7495 - val_pose_output_acc: 0.8234 - val_emotion_output_acc: 0.8512\n",
            "Epoch 36/200\n",
            "Epoch 36/200\n",
            "360/360 [==============================] - 146s 407ms/step - loss: 0.3673 - gender_output_loss: 0.4526 - image_quality_output_loss: 0.5548 - age_output_loss: 0.4472 - weight_output_loss: 0.4142 - bag_output_loss: 0.5121 - footwear_output_loss: 0.5109 - pose_output_loss: 0.4077 - emotion_output_loss: 0.3738 - gender_output_acc: 0.7841 - image_quality_output_acc: 0.7067 - age_output_acc: 0.7994 - weight_output_acc: 0.8177 - bag_output_acc: 0.7433 - footwear_output_acc: 0.7477 - pose_output_acc: 0.8098 - emotion_output_acc: 0.8562 - val_loss: 0.3644 - val_gender_output_loss: 0.4749 - val_image_quality_output_loss: 0.5476 - val_age_output_loss: 0.4455 - val_weight_output_loss: 0.4109 - val_bag_output_loss: 0.5126 - val_footwear_output_loss: 0.4798 - val_pose_output_loss: 0.3932 - val_emotion_output_loss: 0.3799 - val_gender_output_acc: 0.7827 - val_image_quality_output_acc: 0.7062 - val_age_output_acc: 0.7998 - val_weight_output_acc: 0.8196 - val_bag_output_acc: 0.7389 - val_footwear_output_acc: 0.7641 - val_pose_output_acc: 0.8259 - val_emotion_output_acc: 0.8514\n",
            "360/360 [==============================] - 146s 407ms/step - loss: 0.3673 - gender_output_loss: 0.4526 - image_quality_output_loss: 0.5548 - age_output_loss: 0.4472 - weight_output_loss: 0.4142 - bag_output_loss: 0.5121 - footwear_output_loss: 0.5109 - pose_output_loss: 0.4077 - emotion_output_loss: 0.3738 - gender_output_acc: 0.7841 - image_quality_output_acc: 0.7067 - age_output_acc: 0.7994 - weight_output_acc: 0.8177 - bag_output_acc: 0.7433 - footwear_output_acc: 0.7477 - pose_output_acc: 0.8098 - emotion_output_acc: 0.8562 - val_loss: 0.3644 - val_gender_output_loss: 0.4749 - val_image_quality_output_loss: 0.5476 - val_age_output_loss: 0.4455 - val_weight_output_loss: 0.4109 - val_bag_output_loss: 0.5126 - val_footwear_output_loss: 0.4798 - val_pose_output_loss: 0.3932 - val_emotion_output_loss: 0.3799 - val_gender_output_acc: 0.7827 - val_image_quality_output_acc: 0.7062 - val_age_output_acc: 0.7998 - val_weight_output_acc: 0.8196 - val_bag_output_acc: 0.7389 - val_footwear_output_acc: 0.7641 - val_pose_output_acc: 0.8259 - val_emotion_output_acc: 0.8514\n",
            "Epoch 37/200\n",
            "Epoch 37/200\n",
            "360/360 [==============================] - 145s 403ms/step - loss: 0.3653 - gender_output_loss: 0.4460 - image_quality_output_loss: 0.5536 - age_output_loss: 0.4472 - weight_output_loss: 0.4141 - bag_output_loss: 0.5084 - footwear_output_loss: 0.5090 - pose_output_loss: 0.4032 - emotion_output_loss: 0.3717 - gender_output_acc: 0.7908 - image_quality_output_acc: 0.7070 - age_output_acc: 0.7997 - weight_output_acc: 0.8176 - bag_output_acc: 0.7470 - footwear_output_acc: 0.7497 - pose_output_acc: 0.8131 - emotion_output_acc: 0.8567 - val_loss: 0.3594 - val_gender_output_loss: 0.4207 - val_image_quality_output_loss: 0.5457 - val_age_output_loss: 0.4459 - val_weight_output_loss: 0.4136 - val_bag_output_loss: 0.5225 - val_footwear_output_loss: 0.4804 - val_pose_output_loss: 0.3866 - val_emotion_output_loss: 0.3786 - val_gender_output_acc: 0.8046 - val_image_quality_output_acc: 0.7181 - val_age_output_acc: 0.8014 - val_weight_output_acc: 0.8167 - val_bag_output_acc: 0.7354 - val_footwear_output_acc: 0.7682 - val_pose_output_acc: 0.8279 - val_emotion_output_acc: 0.8522\n",
            "360/360 [==============================] - 145s 403ms/step - loss: 0.3653 - gender_output_loss: 0.4460 - image_quality_output_loss: 0.5536 - age_output_loss: 0.4472 - weight_output_loss: 0.4141 - bag_output_loss: 0.5084 - footwear_output_loss: 0.5090 - pose_output_loss: 0.4032 - emotion_output_loss: 0.3717 - gender_output_acc: 0.7908 - image_quality_output_acc: 0.7070 - age_output_acc: 0.7997 - weight_output_acc: 0.8176 - bag_output_acc: 0.7470 - footwear_output_acc: 0.7497 - pose_output_acc: 0.8131 - emotion_output_acc: 0.8567 - val_loss: 0.3594 - val_gender_output_loss: 0.4207 - val_image_quality_output_loss: 0.5457 - val_age_output_loss: 0.4459 - val_weight_output_loss: 0.4136 - val_bag_output_loss: 0.5225 - val_footwear_output_loss: 0.4804 - val_pose_output_loss: 0.3866 - val_emotion_output_loss: 0.3786 - val_gender_output_acc: 0.8046 - val_image_quality_output_acc: 0.7181 - val_age_output_acc: 0.8014 - val_weight_output_acc: 0.8167 - val_bag_output_acc: 0.7354 - val_footwear_output_acc: 0.7682 - val_pose_output_acc: 0.8279 - val_emotion_output_acc: 0.8522\n",
            "Epoch 38/200\n",
            "Epoch 38/200\n",
            "360/360 [==============================] - 144s 401ms/step - loss: 0.3643 - gender_output_loss: 0.4371 - image_quality_output_loss: 0.5537 - age_output_loss: 0.4471 - weight_output_loss: 0.4135 - bag_output_loss: 0.5109 - footwear_output_loss: 0.5025 - pose_output_loss: 0.4060 - emotion_output_loss: 0.3717 - gender_output_acc: 0.7924 - image_quality_output_acc: 0.7087 - age_output_acc: 0.7991 - weight_output_acc: 0.8181 - bag_output_acc: 0.7453 - footwear_output_acc: 0.7540 - pose_output_acc: 0.8127 - emotion_output_acc: 0.8566 - val_loss: 0.3697 - val_gender_output_loss: 0.4861 - val_image_quality_output_loss: 0.5635 - val_age_output_loss: 0.4461 - val_weight_output_loss: 0.4157 - val_bag_output_loss: 0.5148 - val_footwear_output_loss: 0.5074 - val_pose_output_loss: 0.3814 - val_emotion_output_loss: 0.3820 - val_gender_output_acc: 0.7684 - val_image_quality_output_acc: 0.7032 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8202 - val_bag_output_acc: 0.7454 - val_footwear_output_acc: 0.7457 - val_pose_output_acc: 0.8307 - val_emotion_output_acc: 0.8511\n",
            "360/360 [==============================] - 144s 401ms/step - loss: 0.3643 - gender_output_loss: 0.4371 - image_quality_output_loss: 0.5537 - age_output_loss: 0.4471 - weight_output_loss: 0.4135 - bag_output_loss: 0.5109 - footwear_output_loss: 0.5025 - pose_output_loss: 0.4060 - emotion_output_loss: 0.3717 - gender_output_acc: 0.7924 - image_quality_output_acc: 0.7087 - age_output_acc: 0.7991 - weight_output_acc: 0.8181 - bag_output_acc: 0.7453 - footwear_output_acc: 0.7540 - pose_output_acc: 0.8127 - emotion_output_acc: 0.8566 - val_loss: 0.3697 - val_gender_output_loss: 0.4861 - val_image_quality_output_loss: 0.5635 - val_age_output_loss: 0.4461 - val_weight_output_loss: 0.4157 - val_bag_output_loss: 0.5148 - val_footwear_output_loss: 0.5074 - val_pose_output_loss: 0.3814 - val_emotion_output_loss: 0.3820 - val_gender_output_acc: 0.7684 - val_image_quality_output_acc: 0.7032 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8202 - val_bag_output_acc: 0.7454 - val_footwear_output_acc: 0.7457 - val_pose_output_acc: 0.8307 - val_emotion_output_acc: 0.8511\n",
            "Epoch 39/200\n",
            "Epoch 39/200\n",
            "360/360 [==============================] - 145s 401ms/step - loss: 0.3626 - gender_output_loss: 0.4329 - image_quality_output_loss: 0.5530 - age_output_loss: 0.4470 - weight_output_loss: 0.4130 - bag_output_loss: 0.5082 - footwear_output_loss: 0.5017 - pose_output_loss: 0.3992 - emotion_output_loss: 0.3711 - gender_output_acc: 0.7953 - image_quality_output_acc: 0.7093 - age_output_acc: 0.7993 - weight_output_acc: 0.8183 - bag_output_acc: 0.7486 - footwear_output_acc: 0.7527 - pose_output_acc: 0.8145 - emotion_output_acc: 0.8563 - val_loss: 0.3567 - val_gender_output_loss: 0.4174 - val_image_quality_output_loss: 0.5480 - val_age_output_loss: 0.4439 - val_weight_output_loss: 0.4115 - val_bag_output_loss: 0.5078 - val_footwear_output_loss: 0.4835 - val_pose_output_loss: 0.3727 - val_emotion_output_loss: 0.3820 - val_gender_output_acc: 0.8113 - val_image_quality_output_acc: 0.7153 - val_age_output_acc: 0.7997 - val_weight_output_acc: 0.8187 - val_bag_output_acc: 0.7469 - val_footwear_output_acc: 0.7601 - val_pose_output_acc: 0.8381 - val_emotion_output_acc: 0.8522\n",
            "360/360 [==============================] - 145s 401ms/step - loss: 0.3626 - gender_output_loss: 0.4329 - image_quality_output_loss: 0.5530 - age_output_loss: 0.4470 - weight_output_loss: 0.4130 - bag_output_loss: 0.5082 - footwear_output_loss: 0.5017 - pose_output_loss: 0.3992 - emotion_output_loss: 0.3711 - gender_output_acc: 0.7953 - image_quality_output_acc: 0.7093 - age_output_acc: 0.7993 - weight_output_acc: 0.8183 - bag_output_acc: 0.7486 - footwear_output_acc: 0.7527 - pose_output_acc: 0.8145 - emotion_output_acc: 0.8563 - val_loss: 0.3567 - val_gender_output_loss: 0.4174 - val_image_quality_output_loss: 0.5480 - val_age_output_loss: 0.4439 - val_weight_output_loss: 0.4115 - val_bag_output_loss: 0.5078 - val_footwear_output_loss: 0.4835 - val_pose_output_loss: 0.3727 - val_emotion_output_loss: 0.3820 - val_gender_output_acc: 0.8113 - val_image_quality_output_acc: 0.7153 - val_age_output_acc: 0.7997 - val_weight_output_acc: 0.8187 - val_bag_output_acc: 0.7469 - val_footwear_output_acc: 0.7601 - val_pose_output_acc: 0.8381 - val_emotion_output_acc: 0.8522\n",
            "Epoch 40/200\n",
            "Epoch 40/200\n",
            "360/360 [==============================] - 149s 413ms/step - loss: 0.3611 - gender_output_loss: 0.4301 - image_quality_output_loss: 0.5507 - age_output_loss: 0.4458 - weight_output_loss: 0.4134 - bag_output_loss: 0.5072 - footwear_output_loss: 0.5036 - pose_output_loss: 0.3901 - emotion_output_loss: 0.3700 - gender_output_acc: 0.7957 - image_quality_output_acc: 0.7094 - age_output_acc: 0.7999 - weight_output_acc: 0.8178 - bag_output_acc: 0.7449 - footwear_output_acc: 0.7510 - pose_output_acc: 0.8216 - emotion_output_acc: 0.8566 - val_loss: 0.3715 - val_gender_output_loss: 0.5121 - val_image_quality_output_loss: 0.5569 - val_age_output_loss: 0.4506 - val_weight_output_loss: 0.4189 - val_bag_output_loss: 0.5258 - val_footwear_output_loss: 0.4902 - val_pose_output_loss: 0.3730 - val_emotion_output_loss: 0.3874 - val_gender_output_acc: 0.7550 - val_image_quality_output_acc: 0.7106 - val_age_output_acc: 0.8005 - val_weight_output_acc: 0.8199 - val_bag_output_acc: 0.7356 - val_footwear_output_acc: 0.7654 - val_pose_output_acc: 0.8330 - val_emotion_output_acc: 0.8511\n",
            "360/360 [==============================] - 149s 413ms/step - loss: 0.3611 - gender_output_loss: 0.4301 - image_quality_output_loss: 0.5507 - age_output_loss: 0.4458 - weight_output_loss: 0.4134 - bag_output_loss: 0.5072 - footwear_output_loss: 0.5036 - pose_output_loss: 0.3901 - emotion_output_loss: 0.3700 - gender_output_acc: 0.7957 - image_quality_output_acc: 0.7094 - age_output_acc: 0.7999 - weight_output_acc: 0.8178 - bag_output_acc: 0.7449 - footwear_output_acc: 0.7510 - pose_output_acc: 0.8216 - emotion_output_acc: 0.8566 - val_loss: 0.3715 - val_gender_output_loss: 0.5121 - val_image_quality_output_loss: 0.5569 - val_age_output_loss: 0.4506 - val_weight_output_loss: 0.4189 - val_bag_output_loss: 0.5258 - val_footwear_output_loss: 0.4902 - val_pose_output_loss: 0.3730 - val_emotion_output_loss: 0.3874 - val_gender_output_acc: 0.7550 - val_image_quality_output_acc: 0.7106 - val_age_output_acc: 0.8005 - val_weight_output_acc: 0.8199 - val_bag_output_acc: 0.7356 - val_footwear_output_acc: 0.7654 - val_pose_output_acc: 0.8330 - val_emotion_output_acc: 0.8511\n",
            "Epoch 41/200\n",
            "Epoch 41/200\n",
            "360/360 [==============================] - 153s 426ms/step - loss: 0.3600 - gender_output_loss: 0.4244 - image_quality_output_loss: 0.5511 - age_output_loss: 0.4456 - weight_output_loss: 0.4137 - bag_output_loss: 0.5062 - footwear_output_loss: 0.4995 - pose_output_loss: 0.3896 - emotion_output_loss: 0.3703 - gender_output_acc: 0.7995 - image_quality_output_acc: 0.7109 - age_output_acc: 0.7996 - weight_output_acc: 0.8191 - bag_output_acc: 0.7492 - footwear_output_acc: 0.7551 - pose_output_acc: 0.8216 - emotion_output_acc: 0.8565 - val_loss: 0.3808 - val_gender_output_loss: 0.5252 - val_image_quality_output_loss: 0.5680 - val_age_output_loss: 0.4542 - val_weight_output_loss: 0.4229 - val_bag_output_loss: 0.5462 - val_footwear_output_loss: 0.5068 - val_pose_output_loss: 0.3956 - val_emotion_output_loss: 0.3891 - val_gender_output_acc: 0.7470 - val_image_quality_output_acc: 0.7032 - val_age_output_acc: 0.7998 - val_weight_output_acc: 0.8151 - val_bag_output_acc: 0.7188 - val_footwear_output_acc: 0.7502 - val_pose_output_acc: 0.8234 - val_emotion_output_acc: 0.8521\n",
            "360/360 [==============================] - 153s 426ms/step - loss: 0.3600 - gender_output_loss: 0.4244 - image_quality_output_loss: 0.5511 - age_output_loss: 0.4456 - weight_output_loss: 0.4137 - bag_output_loss: 0.5062 - footwear_output_loss: 0.4995 - pose_output_loss: 0.3896 - emotion_output_loss: 0.3703 - gender_output_acc: 0.7995 - image_quality_output_acc: 0.7109 - age_output_acc: 0.7996 - weight_output_acc: 0.8191 - bag_output_acc: 0.7492 - footwear_output_acc: 0.7551 - pose_output_acc: 0.8216 - emotion_output_acc: 0.8565 - val_loss: 0.3808 - val_gender_output_loss: 0.5252 - val_image_quality_output_loss: 0.5680 - val_age_output_loss: 0.4542 - val_weight_output_loss: 0.4229 - val_bag_output_loss: 0.5462 - val_footwear_output_loss: 0.5068 - val_pose_output_loss: 0.3956 - val_emotion_output_loss: 0.3891 - val_gender_output_acc: 0.7470 - val_image_quality_output_acc: 0.7032 - val_age_output_acc: 0.7998 - val_weight_output_acc: 0.8151 - val_bag_output_acc: 0.7188 - val_footwear_output_acc: 0.7502 - val_pose_output_acc: 0.8234 - val_emotion_output_acc: 0.8521\n",
            "Epoch 42/200\n",
            "Epoch 42/200\n",
            "360/360 [==============================] - 158s 438ms/step - loss: 0.3577 - gender_output_loss: 0.4110 - image_quality_output_loss: 0.5495 - age_output_loss: 0.4462 - weight_output_loss: 0.4141 - bag_output_loss: 0.5060 - footwear_output_loss: 0.4990 - pose_output_loss: 0.3813 - emotion_output_loss: 0.3700 - gender_output_acc: 0.8124 - image_quality_output_acc: 0.7106 - age_output_acc: 0.8004 - weight_output_acc: 0.8181 - bag_output_acc: 0.7500 - footwear_output_acc: 0.7563 - pose_output_acc: 0.8259 - emotion_output_acc: 0.8562 - val_loss: 0.3641 - val_gender_output_loss: 0.4655 - val_image_quality_output_loss: 0.5479 - val_age_output_loss: 0.4427 - val_weight_output_loss: 0.4123 - val_bag_output_loss: 0.5231 - val_footwear_output_loss: 0.4818 - val_pose_output_loss: 0.3857 - val_emotion_output_loss: 0.3817 - val_gender_output_acc: 0.7830 - val_image_quality_output_acc: 0.7184 - val_age_output_acc: 0.7997 - val_weight_output_acc: 0.8204 - val_bag_output_acc: 0.7254 - val_footwear_output_acc: 0.7697 - val_pose_output_acc: 0.8312 - val_emotion_output_acc: 0.8509\n",
            "360/360 [==============================] - 158s 438ms/step - loss: 0.3577 - gender_output_loss: 0.4110 - image_quality_output_loss: 0.5495 - age_output_loss: 0.4462 - weight_output_loss: 0.4141 - bag_output_loss: 0.5060 - footwear_output_loss: 0.4990 - pose_output_loss: 0.3813 - emotion_output_loss: 0.3700 - gender_output_acc: 0.8124 - image_quality_output_acc: 0.7106 - age_output_acc: 0.8004 - weight_output_acc: 0.8181 - bag_output_acc: 0.7500 - footwear_output_acc: 0.7563 - pose_output_acc: 0.8259 - emotion_output_acc: 0.8562 - val_loss: 0.3641 - val_gender_output_loss: 0.4655 - val_image_quality_output_loss: 0.5479 - val_age_output_loss: 0.4427 - val_weight_output_loss: 0.4123 - val_bag_output_loss: 0.5231 - val_footwear_output_loss: 0.4818 - val_pose_output_loss: 0.3857 - val_emotion_output_loss: 0.3817 - val_gender_output_acc: 0.7830 - val_image_quality_output_acc: 0.7184 - val_age_output_acc: 0.7997 - val_weight_output_acc: 0.8204 - val_bag_output_acc: 0.7254 - val_footwear_output_acc: 0.7697 - val_pose_output_acc: 0.8312 - val_emotion_output_acc: 0.8509\n",
            "Epoch 43/200\n",
            "Epoch 43/200\n",
            "360/360 [==============================] - 152s 422ms/step - loss: 0.3581 - gender_output_loss: 0.4216 - image_quality_output_loss: 0.5482 - age_output_loss: 0.4456 - weight_output_loss: 0.4126 - bag_output_loss: 0.5046 - footwear_output_loss: 0.5021 - pose_output_loss: 0.3772 - emotion_output_loss: 0.3695 - gender_output_acc: 0.8035 - image_quality_output_acc: 0.7096 - age_output_acc: 0.7995 - weight_output_acc: 0.8188 - bag_output_acc: 0.7501 - footwear_output_acc: 0.7540 - pose_output_acc: 0.8303 - emotion_output_acc: 0.8560 - val_loss: 0.3792 - val_gender_output_loss: 0.5878 - val_image_quality_output_loss: 0.5464 - val_age_output_loss: 0.4499 - val_weight_output_loss: 0.4127 - val_bag_output_loss: 0.5471 - val_footwear_output_loss: 0.4819 - val_pose_output_loss: 0.3880 - val_emotion_output_loss: 0.3785 - val_gender_output_acc: 0.6902 - val_image_quality_output_acc: 0.7128 - val_age_output_acc: 0.7994 - val_weight_output_acc: 0.8208 - val_bag_output_acc: 0.6943 - val_footwear_output_acc: 0.7644 - val_pose_output_acc: 0.8343 - val_emotion_output_acc: 0.8511\n",
            "360/360 [==============================] - 152s 422ms/step - loss: 0.3581 - gender_output_loss: 0.4216 - image_quality_output_loss: 0.5482 - age_output_loss: 0.4456 - weight_output_loss: 0.4126 - bag_output_loss: 0.5046 - footwear_output_loss: 0.5021 - pose_output_loss: 0.3772 - emotion_output_loss: 0.3695 - gender_output_acc: 0.8035 - image_quality_output_acc: 0.7096 - age_output_acc: 0.7995 - weight_output_acc: 0.8188 - bag_output_acc: 0.7501 - footwear_output_acc: 0.7540 - pose_output_acc: 0.8303 - emotion_output_acc: 0.8560 - val_loss: 0.3792 - val_gender_output_loss: 0.5878 - val_image_quality_output_loss: 0.5464 - val_age_output_loss: 0.4499 - val_weight_output_loss: 0.4127 - val_bag_output_loss: 0.5471 - val_footwear_output_loss: 0.4819 - val_pose_output_loss: 0.3880 - val_emotion_output_loss: 0.3785 - val_gender_output_acc: 0.6902 - val_image_quality_output_acc: 0.7128 - val_age_output_acc: 0.7994 - val_weight_output_acc: 0.8208 - val_bag_output_acc: 0.6943 - val_footwear_output_acc: 0.7644 - val_pose_output_acc: 0.8343 - val_emotion_output_acc: 0.8511\n",
            "Epoch 44/200\n",
            "Epoch 44/200\n",
            "360/360 [==============================] - 149s 413ms/step - loss: 0.3561 - gender_output_loss: 0.4073 - image_quality_output_loss: 0.5485 - age_output_loss: 0.4454 - weight_output_loss: 0.4122 - bag_output_loss: 0.5016 - footwear_output_loss: 0.4980 - pose_output_loss: 0.3788 - emotion_output_loss: 0.3691 - gender_output_acc: 0.8095 - image_quality_output_acc: 0.7100 - age_output_acc: 0.7994 - weight_output_acc: 0.8191 - bag_output_acc: 0.7537 - footwear_output_acc: 0.7540 - pose_output_acc: 0.8281 - emotion_output_acc: 0.8565 - val_loss: 0.3894 - val_gender_output_loss: 0.5446 - val_image_quality_output_loss: 0.5492 - val_age_output_loss: 0.4455 - val_weight_output_loss: 0.4110 - val_bag_output_loss: 0.5102 - val_footwear_output_loss: 0.5337 - val_pose_output_loss: 0.5163 - val_emotion_output_loss: 0.3832 - val_gender_output_acc: 0.7746 - val_image_quality_output_acc: 0.7097 - val_age_output_acc: 0.8007 - val_weight_output_acc: 0.8194 - val_bag_output_acc: 0.7460 - val_footwear_output_acc: 0.7397 - val_pose_output_acc: 0.8044 - val_emotion_output_acc: 0.8518\n",
            "360/360 [==============================] - 149s 413ms/step - loss: 0.3561 - gender_output_loss: 0.4073 - image_quality_output_loss: 0.5485 - age_output_loss: 0.4454 - weight_output_loss: 0.4122 - bag_output_loss: 0.5016 - footwear_output_loss: 0.4980 - pose_output_loss: 0.3788 - emotion_output_loss: 0.3691 - gender_output_acc: 0.8095 - image_quality_output_acc: 0.7100 - age_output_acc: 0.7994 - weight_output_acc: 0.8191 - bag_output_acc: 0.7537 - footwear_output_acc: 0.7540 - pose_output_acc: 0.8281 - emotion_output_acc: 0.8565 - val_loss: 0.3894 - val_gender_output_loss: 0.5446 - val_image_quality_output_loss: 0.5492 - val_age_output_loss: 0.4455 - val_weight_output_loss: 0.4110 - val_bag_output_loss: 0.5102 - val_footwear_output_loss: 0.5337 - val_pose_output_loss: 0.5163 - val_emotion_output_loss: 0.3832 - val_gender_output_acc: 0.7746 - val_image_quality_output_acc: 0.7097 - val_age_output_acc: 0.8007 - val_weight_output_acc: 0.8194 - val_bag_output_acc: 0.7460 - val_footwear_output_acc: 0.7397 - val_pose_output_acc: 0.8044 - val_emotion_output_acc: 0.8518\n",
            "Epoch 45/200\n",
            "Epoch 45/200\n",
            "360/360 [==============================] - 149s 414ms/step - loss: 0.3552 - gender_output_loss: 0.4012 - image_quality_output_loss: 0.5480 - age_output_loss: 0.4450 - weight_output_loss: 0.4129 - bag_output_loss: 0.5050 - footwear_output_loss: 0.4972 - pose_output_loss: 0.3726 - emotion_output_loss: 0.3697 - gender_output_acc: 0.8163 - image_quality_output_acc: 0.7127 - age_output_acc: 0.7999 - weight_output_acc: 0.8183 - bag_output_acc: 0.7499 - footwear_output_acc: 0.7579 - pose_output_acc: 0.8311 - emotion_output_acc: 0.8559 - val_loss: 0.3621 - val_gender_output_loss: 0.4180 - val_image_quality_output_loss: 0.5490 - val_age_output_loss: 0.4569 - val_weight_output_loss: 0.4193 - val_bag_output_loss: 0.5066 - val_footwear_output_loss: 0.5178 - val_pose_output_loss: 0.3542 - val_emotion_output_loss: 0.3992 - val_gender_output_acc: 0.8130 - val_image_quality_output_acc: 0.7131 - val_age_output_acc: 0.7991 - val_weight_output_acc: 0.8199 - val_bag_output_acc: 0.7526 - val_footwear_output_acc: 0.7536 - val_pose_output_acc: 0.8553 - val_emotion_output_acc: 0.8502\n",
            "360/360 [==============================] - 149s 414ms/step - loss: 0.3552 - gender_output_loss: 0.4012 - image_quality_output_loss: 0.5480 - age_output_loss: 0.4450 - weight_output_loss: 0.4129 - bag_output_loss: 0.5050 - footwear_output_loss: 0.4972 - pose_output_loss: 0.3726 - emotion_output_loss: 0.3697 - gender_output_acc: 0.8163 - image_quality_output_acc: 0.7127 - age_output_acc: 0.7999 - weight_output_acc: 0.8183 - bag_output_acc: 0.7499 - footwear_output_acc: 0.7579 - pose_output_acc: 0.8311 - emotion_output_acc: 0.8559 - val_loss: 0.3621 - val_gender_output_loss: 0.4180 - val_image_quality_output_loss: 0.5490 - val_age_output_loss: 0.4569 - val_weight_output_loss: 0.4193 - val_bag_output_loss: 0.5066 - val_footwear_output_loss: 0.5178 - val_pose_output_loss: 0.3542 - val_emotion_output_loss: 0.3992 - val_gender_output_acc: 0.8130 - val_image_quality_output_acc: 0.7131 - val_age_output_acc: 0.7991 - val_weight_output_acc: 0.8199 - val_bag_output_acc: 0.7526 - val_footwear_output_acc: 0.7536 - val_pose_output_acc: 0.8553 - val_emotion_output_acc: 0.8502\n",
            "Epoch 46/200\n",
            "Epoch 46/200\n",
            "360/360 [==============================] - 149s 413ms/step - loss: 0.3525 - gender_output_loss: 0.3941 - image_quality_output_loss: 0.5466 - age_output_loss: 0.4453 - weight_output_loss: 0.4126 - bag_output_loss: 0.4989 - footwear_output_loss: 0.4929 - pose_output_loss: 0.3666 - emotion_output_loss: 0.3685 - gender_output_acc: 0.8172 - image_quality_output_acc: 0.7106 - age_output_acc: 0.7997 - weight_output_acc: 0.8187 - bag_output_acc: 0.7561 - footwear_output_acc: 0.7602 - pose_output_acc: 0.8348 - emotion_output_acc: 0.8564 - val_loss: 0.3624 - val_gender_output_loss: 0.4321 - val_image_quality_output_loss: 0.5644 - val_age_output_loss: 0.4529 - val_weight_output_loss: 0.4207 - val_bag_output_loss: 0.5172 - val_footwear_output_loss: 0.4829 - val_pose_output_loss: 0.3550 - val_emotion_output_loss: 0.3986 - val_gender_output_acc: 0.8031 - val_image_quality_output_acc: 0.7070 - val_age_output_acc: 0.8003 - val_weight_output_acc: 0.8142 - val_bag_output_acc: 0.7492 - val_footwear_output_acc: 0.7675 - val_pose_output_acc: 0.8520 - val_emotion_output_acc: 0.8523\n",
            "360/360 [==============================] - 149s 413ms/step - loss: 0.3525 - gender_output_loss: 0.3941 - image_quality_output_loss: 0.5466 - age_output_loss: 0.4453 - weight_output_loss: 0.4126 - bag_output_loss: 0.4989 - footwear_output_loss: 0.4929 - pose_output_loss: 0.3666 - emotion_output_loss: 0.3685 - gender_output_acc: 0.8172 - image_quality_output_acc: 0.7106 - age_output_acc: 0.7997 - weight_output_acc: 0.8187 - bag_output_acc: 0.7561 - footwear_output_acc: 0.7602 - pose_output_acc: 0.8348 - emotion_output_acc: 0.8564 - val_loss: 0.3624 - val_gender_output_loss: 0.4321 - val_image_quality_output_loss: 0.5644 - val_age_output_loss: 0.4529 - val_weight_output_loss: 0.4207 - val_bag_output_loss: 0.5172 - val_footwear_output_loss: 0.4829 - val_pose_output_loss: 0.3550 - val_emotion_output_loss: 0.3986 - val_gender_output_acc: 0.8031 - val_image_quality_output_acc: 0.7070 - val_age_output_acc: 0.8003 - val_weight_output_acc: 0.8142 - val_bag_output_acc: 0.7492 - val_footwear_output_acc: 0.7675 - val_pose_output_acc: 0.8520 - val_emotion_output_acc: 0.8523\n",
            "Epoch 47/200\n",
            "Epoch 47/200\n",
            "360/360 [==============================] - 149s 413ms/step - loss: 0.3532 - gender_output_loss: 0.3977 - image_quality_output_loss: 0.5461 - age_output_loss: 0.4449 - weight_output_loss: 0.4130 - bag_output_loss: 0.5027 - footwear_output_loss: 0.4941 - pose_output_loss: 0.3640 - emotion_output_loss: 0.3692 - gender_output_acc: 0.8161 - image_quality_output_acc: 0.7144 - age_output_acc: 0.7993 - weight_output_acc: 0.8188 - bag_output_acc: 0.7515 - footwear_output_acc: 0.7581 - pose_output_acc: 0.8385 - emotion_output_acc: 0.8563 - val_loss: 0.3744 - val_gender_output_loss: 0.5209 - val_image_quality_output_loss: 0.5596 - val_age_output_loss: 0.4448 - val_weight_output_loss: 0.4146 - val_bag_output_loss: 0.5177 - val_footwear_output_loss: 0.5020 - val_pose_output_loss: 0.4006 - val_emotion_output_loss: 0.3834 - val_gender_output_acc: 0.7445 - val_image_quality_output_acc: 0.7024 - val_age_output_acc: 0.8002 - val_weight_output_acc: 0.8165 - val_bag_output_acc: 0.7394 - val_footwear_output_acc: 0.7513 - val_pose_output_acc: 0.8223 - val_emotion_output_acc: 0.8519\n",
            "360/360 [==============================] - 149s 413ms/step - loss: 0.3532 - gender_output_loss: 0.3977 - image_quality_output_loss: 0.5461 - age_output_loss: 0.4449 - weight_output_loss: 0.4130 - bag_output_loss: 0.5027 - footwear_output_loss: 0.4941 - pose_output_loss: 0.3640 - emotion_output_loss: 0.3692 - gender_output_acc: 0.8161 - image_quality_output_acc: 0.7144 - age_output_acc: 0.7993 - weight_output_acc: 0.8188 - bag_output_acc: 0.7515 - footwear_output_acc: 0.7581 - pose_output_acc: 0.8385 - emotion_output_acc: 0.8563 - val_loss: 0.3744 - val_gender_output_loss: 0.5209 - val_image_quality_output_loss: 0.5596 - val_age_output_loss: 0.4448 - val_weight_output_loss: 0.4146 - val_bag_output_loss: 0.5177 - val_footwear_output_loss: 0.5020 - val_pose_output_loss: 0.4006 - val_emotion_output_loss: 0.3834 - val_gender_output_acc: 0.7445 - val_image_quality_output_acc: 0.7024 - val_age_output_acc: 0.8002 - val_weight_output_acc: 0.8165 - val_bag_output_acc: 0.7394 - val_footwear_output_acc: 0.7513 - val_pose_output_acc: 0.8223 - val_emotion_output_acc: 0.8519\n",
            "Epoch 48/200\n",
            "Epoch 48/200\n",
            "360/360 [==============================] - 149s 414ms/step - loss: 0.3520 - gender_output_loss: 0.3925 - image_quality_output_loss: 0.5459 - age_output_loss: 0.4442 - weight_output_loss: 0.4119 - bag_output_loss: 0.4992 - footwear_output_loss: 0.4942 - pose_output_loss: 0.3642 - emotion_output_loss: 0.3681 - gender_output_acc: 0.8181 - image_quality_output_acc: 0.7144 - age_output_acc: 0.8001 - weight_output_acc: 0.8191 - bag_output_acc: 0.7552 - footwear_output_acc: 0.7583 - pose_output_acc: 0.8367 - emotion_output_acc: 0.8566 - val_loss: 0.3591 - val_gender_output_loss: 0.3956 - val_image_quality_output_loss: 0.5564 - val_age_output_loss: 0.4511 - val_weight_output_loss: 0.4162 - val_bag_output_loss: 0.5076 - val_footwear_output_loss: 0.4953 - val_pose_output_loss: 0.3775 - val_emotion_output_loss: 0.3909 - val_gender_output_acc: 0.8207 - val_image_quality_output_acc: 0.7090 - val_age_output_acc: 0.8001 - val_weight_output_acc: 0.8197 - val_bag_output_acc: 0.7503 - val_footwear_output_acc: 0.7629 - val_pose_output_acc: 0.8332 - val_emotion_output_acc: 0.8507\n",
            "360/360 [==============================] - 149s 414ms/step - loss: 0.3520 - gender_output_loss: 0.3925 - image_quality_output_loss: 0.5459 - age_output_loss: 0.4442 - weight_output_loss: 0.4119 - bag_output_loss: 0.4992 - footwear_output_loss: 0.4942 - pose_output_loss: 0.3642 - emotion_output_loss: 0.3681 - gender_output_acc: 0.8181 - image_quality_output_acc: 0.7144 - age_output_acc: 0.8001 - weight_output_acc: 0.8191 - bag_output_acc: 0.7552 - footwear_output_acc: 0.7583 - pose_output_acc: 0.8367 - emotion_output_acc: 0.8566 - val_loss: 0.3591 - val_gender_output_loss: 0.3956 - val_image_quality_output_loss: 0.5564 - val_age_output_loss: 0.4511 - val_weight_output_loss: 0.4162 - val_bag_output_loss: 0.5076 - val_footwear_output_loss: 0.4953 - val_pose_output_loss: 0.3775 - val_emotion_output_loss: 0.3909 - val_gender_output_acc: 0.8207 - val_image_quality_output_acc: 0.7090 - val_age_output_acc: 0.8001 - val_weight_output_acc: 0.8197 - val_bag_output_acc: 0.7503 - val_footwear_output_acc: 0.7629 - val_pose_output_acc: 0.8332 - val_emotion_output_acc: 0.8507\n",
            "Epoch 49/200\n",
            "Epoch 49/200\n",
            "360/360 [==============================] - 149s 415ms/step - loss: 0.3508 - gender_output_loss: 0.3890 - image_quality_output_loss: 0.5460 - age_output_loss: 0.4446 - weight_output_loss: 0.4118 - bag_output_loss: 0.4979 - footwear_output_loss: 0.4935 - pose_output_loss: 0.3576 - emotion_output_loss: 0.3680 - gender_output_acc: 0.8237 - image_quality_output_acc: 0.7117 - age_output_acc: 0.7998 - weight_output_acc: 0.8198 - bag_output_acc: 0.7565 - footwear_output_acc: 0.7579 - pose_output_acc: 0.8399 - emotion_output_acc: 0.8559 - val_loss: 0.3467 - val_gender_output_loss: 0.3718 - val_image_quality_output_loss: 0.5416 - val_age_output_loss: 0.4428 - val_weight_output_loss: 0.4125 - val_bag_output_loss: 0.5005 - val_footwear_output_loss: 0.4761 - val_pose_output_loss: 0.3413 - val_emotion_output_loss: 0.3800 - val_gender_output_acc: 0.8306 - val_image_quality_output_acc: 0.7149 - val_age_output_acc: 0.8013 - val_weight_output_acc: 0.8178 - val_bag_output_acc: 0.7521 - val_footwear_output_acc: 0.7695 - val_pose_output_acc: 0.8504 - val_emotion_output_acc: 0.8522\n",
            "360/360 [==============================] - 149s 415ms/step - loss: 0.3508 - gender_output_loss: 0.3890 - image_quality_output_loss: 0.5460 - age_output_loss: 0.4446 - weight_output_loss: 0.4118 - bag_output_loss: 0.4979 - footwear_output_loss: 0.4935 - pose_output_loss: 0.3576 - emotion_output_loss: 0.3680 - gender_output_acc: 0.8237 - image_quality_output_acc: 0.7117 - age_output_acc: 0.7998 - weight_output_acc: 0.8198 - bag_output_acc: 0.7565 - footwear_output_acc: 0.7579 - pose_output_acc: 0.8399 - emotion_output_acc: 0.8559 - val_loss: 0.3467 - val_gender_output_loss: 0.3718 - val_image_quality_output_loss: 0.5416 - val_age_output_loss: 0.4428 - val_weight_output_loss: 0.4125 - val_bag_output_loss: 0.5005 - val_footwear_output_loss: 0.4761 - val_pose_output_loss: 0.3413 - val_emotion_output_loss: 0.3800 - val_gender_output_acc: 0.8306 - val_image_quality_output_acc: 0.7149 - val_age_output_acc: 0.8013 - val_weight_output_acc: 0.8178 - val_bag_output_acc: 0.7521 - val_footwear_output_acc: 0.7695 - val_pose_output_acc: 0.8504 - val_emotion_output_acc: 0.8522\n",
            "Epoch 50/200\n",
            "Epoch 50/200\n",
            "360/360 [==============================] - 147s 409ms/step - loss: 0.3489 - gender_output_loss: 0.3814 - image_quality_output_loss: 0.5430 - age_output_loss: 0.4451 - weight_output_loss: 0.4114 - bag_output_loss: 0.4976 - footwear_output_loss: 0.4904 - pose_output_loss: 0.3523 - emotion_output_loss: 0.3677 - gender_output_acc: 0.8260 - image_quality_output_acc: 0.7134 - age_output_acc: 0.7995 - weight_output_acc: 0.8188 - bag_output_acc: 0.7569 - footwear_output_acc: 0.7596 - pose_output_acc: 0.8425 - emotion_output_acc: 0.8571 - val_loss: 0.3515 - val_gender_output_loss: 0.3933 - val_image_quality_output_loss: 0.5511 - val_age_output_loss: 0.4458 - val_weight_output_loss: 0.4118 - val_bag_output_loss: 0.5078 - val_footwear_output_loss: 0.4806 - val_pose_output_loss: 0.3444 - val_emotion_output_loss: 0.3804 - val_gender_output_acc: 0.8232 - val_image_quality_output_acc: 0.7108 - val_age_output_acc: 0.8003 - val_weight_output_acc: 0.8202 - val_bag_output_acc: 0.7510 - val_footwear_output_acc: 0.7677 - val_pose_output_acc: 0.8421 - val_emotion_output_acc: 0.8518\n",
            "360/360 [==============================] - 147s 409ms/step - loss: 0.3489 - gender_output_loss: 0.3814 - image_quality_output_loss: 0.5430 - age_output_loss: 0.4451 - weight_output_loss: 0.4114 - bag_output_loss: 0.4976 - footwear_output_loss: 0.4904 - pose_output_loss: 0.3523 - emotion_output_loss: 0.3677 - gender_output_acc: 0.8260 - image_quality_output_acc: 0.7134 - age_output_acc: 0.7995 - weight_output_acc: 0.8188 - bag_output_acc: 0.7569 - footwear_output_acc: 0.7596 - pose_output_acc: 0.8425 - emotion_output_acc: 0.8571 - val_loss: 0.3515 - val_gender_output_loss: 0.3933 - val_image_quality_output_loss: 0.5511 - val_age_output_loss: 0.4458 - val_weight_output_loss: 0.4118 - val_bag_output_loss: 0.5078 - val_footwear_output_loss: 0.4806 - val_pose_output_loss: 0.3444 - val_emotion_output_loss: 0.3804 - val_gender_output_acc: 0.8232 - val_image_quality_output_acc: 0.7108 - val_age_output_acc: 0.8003 - val_weight_output_acc: 0.8202 - val_bag_output_acc: 0.7510 - val_footwear_output_acc: 0.7677 - val_pose_output_acc: 0.8421 - val_emotion_output_acc: 0.8518\n",
            "Epoch 51/200\n",
            "Epoch 51/200\n",
            "360/360 [==============================] - 148s 411ms/step - loss: 0.3485 - gender_output_loss: 0.3821 - image_quality_output_loss: 0.5418 - age_output_loss: 0.4450 - weight_output_loss: 0.4117 - bag_output_loss: 0.4962 - footwear_output_loss: 0.4914 - pose_output_loss: 0.3505 - emotion_output_loss: 0.3664 - gender_output_acc: 0.8212 - image_quality_output_acc: 0.7172 - age_output_acc: 0.8006 - weight_output_acc: 0.8189 - bag_output_acc: 0.7555 - footwear_output_acc: 0.7602 - pose_output_acc: 0.8459 - emotion_output_acc: 0.8564 - val_loss: 0.3640 - val_gender_output_loss: 0.4408 - val_image_quality_output_loss: 0.5701 - val_age_output_loss: 0.4478 - val_weight_output_loss: 0.4156 - val_bag_output_loss: 0.4969 - val_footwear_output_loss: 0.4794 - val_pose_output_loss: 0.4050 - val_emotion_output_loss: 0.3841 - val_gender_output_acc: 0.8016 - val_image_quality_output_acc: 0.7116 - val_age_output_acc: 0.7994 - val_weight_output_acc: 0.8162 - val_bag_output_acc: 0.7586 - val_footwear_output_acc: 0.7703 - val_pose_output_acc: 0.8130 - val_emotion_output_acc: 0.8513\n",
            "360/360 [==============================] - 148s 411ms/step - loss: 0.3485 - gender_output_loss: 0.3821 - image_quality_output_loss: 0.5418 - age_output_loss: 0.4450 - weight_output_loss: 0.4117 - bag_output_loss: 0.4962 - footwear_output_loss: 0.4914 - pose_output_loss: 0.3505 - emotion_output_loss: 0.3664 - gender_output_acc: 0.8212 - image_quality_output_acc: 0.7172 - age_output_acc: 0.8006 - weight_output_acc: 0.8189 - bag_output_acc: 0.7555 - footwear_output_acc: 0.7602 - pose_output_acc: 0.8459 - emotion_output_acc: 0.8564 - val_loss: 0.3640 - val_gender_output_loss: 0.4408 - val_image_quality_output_loss: 0.5701 - val_age_output_loss: 0.4478 - val_weight_output_loss: 0.4156 - val_bag_output_loss: 0.4969 - val_footwear_output_loss: 0.4794 - val_pose_output_loss: 0.4050 - val_emotion_output_loss: 0.3841 - val_gender_output_acc: 0.8016 - val_image_quality_output_acc: 0.7116 - val_age_output_acc: 0.7994 - val_weight_output_acc: 0.8162 - val_bag_output_acc: 0.7586 - val_footwear_output_acc: 0.7703 - val_pose_output_acc: 0.8130 - val_emotion_output_acc: 0.8513\n",
            "Epoch 52/200\n",
            "Epoch 52/200\n",
            "360/360 [==============================] - 148s 410ms/step - loss: 0.3480 - gender_output_loss: 0.3776 - image_quality_output_loss: 0.5458 - age_output_loss: 0.4437 - weight_output_loss: 0.4109 - bag_output_loss: 0.4943 - footwear_output_loss: 0.4905 - pose_output_loss: 0.3507 - emotion_output_loss: 0.3667 - gender_output_acc: 0.8308 - image_quality_output_acc: 0.7137 - age_output_acc: 0.7999 - weight_output_acc: 0.8194 - bag_output_acc: 0.7602 - footwear_output_acc: 0.7610 - pose_output_acc: 0.8433 - emotion_output_acc: 0.8566 - val_loss: 0.3455 - val_gender_output_loss: 0.3681 - val_image_quality_output_loss: 0.5423 - val_age_output_loss: 0.4402 - val_weight_output_loss: 0.4104 - val_bag_output_loss: 0.4980 - val_footwear_output_loss: 0.4735 - val_pose_output_loss: 0.3377 - val_emotion_output_loss: 0.3848 - val_gender_output_acc: 0.8450 - val_image_quality_output_acc: 0.7140 - val_age_output_acc: 0.8001 - val_weight_output_acc: 0.8192 - val_bag_output_acc: 0.7564 - val_footwear_output_acc: 0.7705 - val_pose_output_acc: 0.8492 - val_emotion_output_acc: 0.8507\n",
            "360/360 [==============================] - 148s 410ms/step - loss: 0.3480 - gender_output_loss: 0.3776 - image_quality_output_loss: 0.5458 - age_output_loss: 0.4437 - weight_output_loss: 0.4109 - bag_output_loss: 0.4943 - footwear_output_loss: 0.4905 - pose_output_loss: 0.3507 - emotion_output_loss: 0.3667 - gender_output_acc: 0.8308 - image_quality_output_acc: 0.7137 - age_output_acc: 0.7999 - weight_output_acc: 0.8194 - bag_output_acc: 0.7602 - footwear_output_acc: 0.7610 - pose_output_acc: 0.8433 - emotion_output_acc: 0.8566 - val_loss: 0.3455 - val_gender_output_loss: 0.3681 - val_image_quality_output_loss: 0.5423 - val_age_output_loss: 0.4402 - val_weight_output_loss: 0.4104 - val_bag_output_loss: 0.4980 - val_footwear_output_loss: 0.4735 - val_pose_output_loss: 0.3377 - val_emotion_output_loss: 0.3848 - val_gender_output_acc: 0.8450 - val_image_quality_output_acc: 0.7140 - val_age_output_acc: 0.8001 - val_weight_output_acc: 0.8192 - val_bag_output_acc: 0.7564 - val_footwear_output_acc: 0.7705 - val_pose_output_acc: 0.8492 - val_emotion_output_acc: 0.8507\n",
            "Epoch 53/200\n",
            "Epoch 53/200\n",
            "360/360 [==============================] - 145s 402ms/step - loss: 0.3457 - gender_output_loss: 0.3708 - image_quality_output_loss: 0.5393 - age_output_loss: 0.4436 - weight_output_loss: 0.4111 - bag_output_loss: 0.4931 - footwear_output_loss: 0.4890 - pose_output_loss: 0.3424 - emotion_output_loss: 0.3677 - gender_output_acc: 0.8360 - image_quality_output_acc: 0.7183 - age_output_acc: 0.7999 - weight_output_acc: 0.8188 - bag_output_acc: 0.7615 - footwear_output_acc: 0.7593 - pose_output_acc: 0.8464 - emotion_output_acc: 0.8564 - val_loss: 0.3449 - val_gender_output_loss: 0.3514 - val_image_quality_output_loss: 0.5549 - val_age_output_loss: 0.4431 - val_weight_output_loss: 0.4120 - val_bag_output_loss: 0.4985 - val_footwear_output_loss: 0.4762 - val_pose_output_loss: 0.3338 - val_emotion_output_loss: 0.3791 - val_gender_output_acc: 0.8544 - val_image_quality_output_acc: 0.7059 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8192 - val_bag_output_acc: 0.7556 - val_footwear_output_acc: 0.7665 - val_pose_output_acc: 0.8557 - val_emotion_output_acc: 0.8513\n",
            "360/360 [==============================] - 145s 402ms/step - loss: 0.3457 - gender_output_loss: 0.3708 - image_quality_output_loss: 0.5393 - age_output_loss: 0.4436 - weight_output_loss: 0.4111 - bag_output_loss: 0.4931 - footwear_output_loss: 0.4890 - pose_output_loss: 0.3424 - emotion_output_loss: 0.3677 - gender_output_acc: 0.8360 - image_quality_output_acc: 0.7183 - age_output_acc: 0.7999 - weight_output_acc: 0.8188 - bag_output_acc: 0.7615 - footwear_output_acc: 0.7593 - pose_output_acc: 0.8464 - emotion_output_acc: 0.8564 - val_loss: 0.3449 - val_gender_output_loss: 0.3514 - val_image_quality_output_loss: 0.5549 - val_age_output_loss: 0.4431 - val_weight_output_loss: 0.4120 - val_bag_output_loss: 0.4985 - val_footwear_output_loss: 0.4762 - val_pose_output_loss: 0.3338 - val_emotion_output_loss: 0.3791 - val_gender_output_acc: 0.8544 - val_image_quality_output_acc: 0.7059 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8192 - val_bag_output_acc: 0.7556 - val_footwear_output_acc: 0.7665 - val_pose_output_acc: 0.8557 - val_emotion_output_acc: 0.8513\n",
            "Epoch 54/200\n",
            "Epoch 54/200\n",
            "360/360 [==============================] - 152s 423ms/step - loss: 0.3455 - gender_output_loss: 0.3692 - image_quality_output_loss: 0.5410 - age_output_loss: 0.4438 - weight_output_loss: 0.4098 - bag_output_loss: 0.4929 - footwear_output_loss: 0.4883 - pose_output_loss: 0.3436 - emotion_output_loss: 0.3663 - gender_output_acc: 0.8312 - image_quality_output_acc: 0.7170 - age_output_acc: 0.8003 - weight_output_acc: 0.8192 - bag_output_acc: 0.7613 - footwear_output_acc: 0.7631 - pose_output_acc: 0.8464 - emotion_output_acc: 0.8566 - val_loss: 0.3497 - val_gender_output_loss: 0.3902 - val_image_quality_output_loss: 0.5453 - val_age_output_loss: 0.4451 - val_weight_output_loss: 0.4120 - val_bag_output_loss: 0.5015 - val_footwear_output_loss: 0.4896 - val_pose_output_loss: 0.3287 - val_emotion_output_loss: 0.3848 - val_gender_output_acc: 0.8425 - val_image_quality_output_acc: 0.7135 - val_age_output_acc: 0.7996 - val_weight_output_acc: 0.8180 - val_bag_output_acc: 0.7606 - val_footwear_output_acc: 0.7581 - val_pose_output_acc: 0.8618 - val_emotion_output_acc: 0.8487\n",
            "360/360 [==============================] - 152s 423ms/step - loss: 0.3455 - gender_output_loss: 0.3692 - image_quality_output_loss: 0.5410 - age_output_loss: 0.4438 - weight_output_loss: 0.4098 - bag_output_loss: 0.4929 - footwear_output_loss: 0.4883 - pose_output_loss: 0.3436 - emotion_output_loss: 0.3663 - gender_output_acc: 0.8312 - image_quality_output_acc: 0.7170 - age_output_acc: 0.8003 - weight_output_acc: 0.8192 - bag_output_acc: 0.7613 - footwear_output_acc: 0.7631 - pose_output_acc: 0.8464 - emotion_output_acc: 0.8566 - val_loss: 0.3497 - val_gender_output_loss: 0.3902 - val_image_quality_output_loss: 0.5453 - val_age_output_loss: 0.4451 - val_weight_output_loss: 0.4120 - val_bag_output_loss: 0.5015 - val_footwear_output_loss: 0.4896 - val_pose_output_loss: 0.3287 - val_emotion_output_loss: 0.3848 - val_gender_output_acc: 0.8425 - val_image_quality_output_acc: 0.7135 - val_age_output_acc: 0.7996 - val_weight_output_acc: 0.8180 - val_bag_output_acc: 0.7606 - val_footwear_output_acc: 0.7581 - val_pose_output_acc: 0.8618 - val_emotion_output_acc: 0.8487\n",
            "Epoch 55/200\n",
            "Epoch 55/200\n",
            "360/360 [==============================] - 154s 429ms/step - loss: 0.3444 - gender_output_loss: 0.3620 - image_quality_output_loss: 0.5417 - age_output_loss: 0.4431 - weight_output_loss: 0.4108 - bag_output_loss: 0.4909 - footwear_output_loss: 0.4887 - pose_output_loss: 0.3408 - emotion_output_loss: 0.3663 - gender_output_acc: 0.8378 - image_quality_output_acc: 0.7169 - age_output_acc: 0.7995 - weight_output_acc: 0.8198 - bag_output_acc: 0.7617 - footwear_output_acc: 0.7613 - pose_output_acc: 0.8498 - emotion_output_acc: 0.8567 - val_loss: 0.3550 - val_gender_output_loss: 0.3853 - val_image_quality_output_loss: 0.5522 - val_age_output_loss: 0.4480 - val_weight_output_loss: 0.4157 - val_bag_output_loss: 0.5137 - val_footwear_output_loss: 0.4772 - val_pose_output_loss: 0.3603 - val_emotion_output_loss: 0.3975 - val_gender_output_acc: 0.8418 - val_image_quality_output_acc: 0.7103 - val_age_output_acc: 0.8002 - val_weight_output_acc: 0.8149 - val_bag_output_acc: 0.7512 - val_footwear_output_acc: 0.7632 - val_pose_output_acc: 0.8476 - val_emotion_output_acc: 0.8522\n",
            "360/360 [==============================] - 154s 429ms/step - loss: 0.3444 - gender_output_loss: 0.3620 - image_quality_output_loss: 0.5417 - age_output_loss: 0.4431 - weight_output_loss: 0.4108 - bag_output_loss: 0.4909 - footwear_output_loss: 0.4887 - pose_output_loss: 0.3408 - emotion_output_loss: 0.3663 - gender_output_acc: 0.8378 - image_quality_output_acc: 0.7169 - age_output_acc: 0.7995 - weight_output_acc: 0.8198 - bag_output_acc: 0.7617 - footwear_output_acc: 0.7613 - pose_output_acc: 0.8498 - emotion_output_acc: 0.8567 - val_loss: 0.3550 - val_gender_output_loss: 0.3853 - val_image_quality_output_loss: 0.5522 - val_age_output_loss: 0.4480 - val_weight_output_loss: 0.4157 - val_bag_output_loss: 0.5137 - val_footwear_output_loss: 0.4772 - val_pose_output_loss: 0.3603 - val_emotion_output_loss: 0.3975 - val_gender_output_acc: 0.8418 - val_image_quality_output_acc: 0.7103 - val_age_output_acc: 0.8002 - val_weight_output_acc: 0.8149 - val_bag_output_acc: 0.7512 - val_footwear_output_acc: 0.7632 - val_pose_output_acc: 0.8476 - val_emotion_output_acc: 0.8522\n",
            "Epoch 56/200\n",
            "Epoch 56/200\n",
            "360/360 [==============================] - 151s 419ms/step - loss: 0.3417 - gender_output_loss: 0.3548 - image_quality_output_loss: 0.5392 - age_output_loss: 0.4434 - weight_output_loss: 0.4090 - bag_output_loss: 0.4884 - footwear_output_loss: 0.4864 - pose_output_loss: 0.3289 - emotion_output_loss: 0.3665 - gender_output_acc: 0.8431 - image_quality_output_acc: 0.7177 - age_output_acc: 0.7992 - weight_output_acc: 0.8197 - bag_output_acc: 0.7639 - footwear_output_acc: 0.7626 - pose_output_acc: 0.8557 - emotion_output_acc: 0.8561 - val_loss: 0.3474 - val_gender_output_loss: 0.4076 - val_image_quality_output_loss: 0.5396 - val_age_output_loss: 0.4416 - val_weight_output_loss: 0.4126 - val_bag_output_loss: 0.5046 - val_footwear_output_loss: 0.4701 - val_pose_output_loss: 0.3175 - val_emotion_output_loss: 0.3809 - val_gender_output_acc: 0.8197 - val_image_quality_output_acc: 0.7128 - val_age_output_acc: 0.8008 - val_weight_output_acc: 0.8212 - val_bag_output_acc: 0.7558 - val_footwear_output_acc: 0.7722 - val_pose_output_acc: 0.8616 - val_emotion_output_acc: 0.8512\n",
            "360/360 [==============================] - 151s 419ms/step - loss: 0.3417 - gender_output_loss: 0.3548 - image_quality_output_loss: 0.5392 - age_output_loss: 0.4434 - weight_output_loss: 0.4090 - bag_output_loss: 0.4884 - footwear_output_loss: 0.4864 - pose_output_loss: 0.3289 - emotion_output_loss: 0.3665 - gender_output_acc: 0.8431 - image_quality_output_acc: 0.7177 - age_output_acc: 0.7992 - weight_output_acc: 0.8197 - bag_output_acc: 0.7639 - footwear_output_acc: 0.7626 - pose_output_acc: 0.8557 - emotion_output_acc: 0.8561 - val_loss: 0.3474 - val_gender_output_loss: 0.4076 - val_image_quality_output_loss: 0.5396 - val_age_output_loss: 0.4416 - val_weight_output_loss: 0.4126 - val_bag_output_loss: 0.5046 - val_footwear_output_loss: 0.4701 - val_pose_output_loss: 0.3175 - val_emotion_output_loss: 0.3809 - val_gender_output_acc: 0.8197 - val_image_quality_output_acc: 0.7128 - val_age_output_acc: 0.8008 - val_weight_output_acc: 0.8212 - val_bag_output_acc: 0.7558 - val_footwear_output_acc: 0.7722 - val_pose_output_acc: 0.8616 - val_emotion_output_acc: 0.8512\n",
            "Epoch 57/200\n",
            "Epoch 57/200\n",
            "360/360 [==============================] - 152s 423ms/step - loss: 0.3417 - gender_output_loss: 0.3552 - image_quality_output_loss: 0.5388 - age_output_loss: 0.4432 - weight_output_loss: 0.4096 - bag_output_loss: 0.4895 - footwear_output_loss: 0.4807 - pose_output_loss: 0.3345 - emotion_output_loss: 0.3657 - gender_output_acc: 0.8395 - image_quality_output_acc: 0.7176 - age_output_acc: 0.7998 - weight_output_acc: 0.8195 - bag_output_acc: 0.7632 - footwear_output_acc: 0.7664 - pose_output_acc: 0.8542 - emotion_output_acc: 0.8566 - val_loss: 0.3607 - val_gender_output_loss: 0.4255 - val_image_quality_output_loss: 0.5445 - val_age_output_loss: 0.4448 - val_weight_output_loss: 0.4140 - val_bag_output_loss: 0.5149 - val_footwear_output_loss: 0.4839 - val_pose_output_loss: 0.3960 - val_emotion_output_loss: 0.3831 - val_gender_output_acc: 0.8167 - val_image_quality_output_acc: 0.7135 - val_age_output_acc: 0.7998 - val_weight_output_acc: 0.8194 - val_bag_output_acc: 0.7485 - val_footwear_output_acc: 0.7607 - val_pose_output_acc: 0.8368 - val_emotion_output_acc: 0.8492\n",
            "360/360 [==============================] - 152s 423ms/step - loss: 0.3417 - gender_output_loss: 0.3552 - image_quality_output_loss: 0.5388 - age_output_loss: 0.4432 - weight_output_loss: 0.4096 - bag_output_loss: 0.4895 - footwear_output_loss: 0.4807 - pose_output_loss: 0.3345 - emotion_output_loss: 0.3657 - gender_output_acc: 0.8395 - image_quality_output_acc: 0.7176 - age_output_acc: 0.7998 - weight_output_acc: 0.8195 - bag_output_acc: 0.7632 - footwear_output_acc: 0.7664 - pose_output_acc: 0.8542 - emotion_output_acc: 0.8566 - val_loss: 0.3607 - val_gender_output_loss: 0.4255 - val_image_quality_output_loss: 0.5445 - val_age_output_loss: 0.4448 - val_weight_output_loss: 0.4140 - val_bag_output_loss: 0.5149 - val_footwear_output_loss: 0.4839 - val_pose_output_loss: 0.3960 - val_emotion_output_loss: 0.3831 - val_gender_output_acc: 0.8167 - val_image_quality_output_acc: 0.7135 - val_age_output_acc: 0.7998 - val_weight_output_acc: 0.8194 - val_bag_output_acc: 0.7485 - val_footwear_output_acc: 0.7607 - val_pose_output_acc: 0.8368 - val_emotion_output_acc: 0.8492\n",
            "Epoch 58/200\n",
            "Epoch 58/200\n",
            "360/360 [==============================] - 153s 424ms/step - loss: 0.3402 - gender_output_loss: 0.3464 - image_quality_output_loss: 0.5379 - age_output_loss: 0.4426 - weight_output_loss: 0.4086 - bag_output_loss: 0.4851 - footwear_output_loss: 0.4865 - pose_output_loss: 0.3297 - emotion_output_loss: 0.3656 - gender_output_acc: 0.8503 - image_quality_output_acc: 0.7187 - age_output_acc: 0.8000 - weight_output_acc: 0.8203 - bag_output_acc: 0.7683 - footwear_output_acc: 0.7621 - pose_output_acc: 0.8571 - emotion_output_acc: 0.8567 - val_loss: 0.3697 - val_gender_output_loss: 0.5090 - val_image_quality_output_loss: 0.5452 - val_age_output_loss: 0.4452 - val_weight_output_loss: 0.4142 - val_bag_output_loss: 0.5051 - val_footwear_output_loss: 0.4814 - val_pose_output_loss: 0.4128 - val_emotion_output_loss: 0.3837 - val_gender_output_acc: 0.7872 - val_image_quality_output_acc: 0.7085 - val_age_output_acc: 0.8018 - val_weight_output_acc: 0.8198 - val_bag_output_acc: 0.7538 - val_footwear_output_acc: 0.7632 - val_pose_output_acc: 0.8358 - val_emotion_output_acc: 0.8493\n",
            "360/360 [==============================] - 153s 424ms/step - loss: 0.3402 - gender_output_loss: 0.3464 - image_quality_output_loss: 0.5379 - age_output_loss: 0.4426 - weight_output_loss: 0.4086 - bag_output_loss: 0.4851 - footwear_output_loss: 0.4865 - pose_output_loss: 0.3297 - emotion_output_loss: 0.3656 - gender_output_acc: 0.8503 - image_quality_output_acc: 0.7187 - age_output_acc: 0.8000 - weight_output_acc: 0.8203 - bag_output_acc: 0.7683 - footwear_output_acc: 0.7621 - pose_output_acc: 0.8571 - emotion_output_acc: 0.8567 - val_loss: 0.3697 - val_gender_output_loss: 0.5090 - val_image_quality_output_loss: 0.5452 - val_age_output_loss: 0.4452 - val_weight_output_loss: 0.4142 - val_bag_output_loss: 0.5051 - val_footwear_output_loss: 0.4814 - val_pose_output_loss: 0.4128 - val_emotion_output_loss: 0.3837 - val_gender_output_acc: 0.7872 - val_image_quality_output_acc: 0.7085 - val_age_output_acc: 0.8018 - val_weight_output_acc: 0.8198 - val_bag_output_acc: 0.7538 - val_footwear_output_acc: 0.7632 - val_pose_output_acc: 0.8358 - val_emotion_output_acc: 0.8493\n",
            "Epoch 59/200\n",
            "Epoch 59/200\n",
            "360/360 [==============================] - 150s 417ms/step - loss: 0.3394 - gender_output_loss: 0.3481 - image_quality_output_loss: 0.5386 - age_output_loss: 0.4421 - weight_output_loss: 0.4089 - bag_output_loss: 0.4874 - footwear_output_loss: 0.4817 - pose_output_loss: 0.3227 - emotion_output_loss: 0.3646 - gender_output_acc: 0.8465 - image_quality_output_acc: 0.7167 - age_output_acc: 0.8003 - weight_output_acc: 0.8188 - bag_output_acc: 0.7666 - footwear_output_acc: 0.7638 - pose_output_acc: 0.8590 - emotion_output_acc: 0.8564 - val_loss: 0.3427 - val_gender_output_loss: 0.3475 - val_image_quality_output_loss: 0.5485 - val_age_output_loss: 0.4419 - val_weight_output_loss: 0.4115 - val_bag_output_loss: 0.5055 - val_footwear_output_loss: 0.4803 - val_pose_output_loss: 0.3126 - val_emotion_output_loss: 0.3788 - val_gender_output_acc: 0.8681 - val_image_quality_output_acc: 0.7083 - val_age_output_acc: 0.8018 - val_weight_output_acc: 0.8196 - val_bag_output_acc: 0.7551 - val_footwear_output_acc: 0.7652 - val_pose_output_acc: 0.8666 - val_emotion_output_acc: 0.8493\n",
            "360/360 [==============================] - 150s 417ms/step - loss: 0.3394 - gender_output_loss: 0.3481 - image_quality_output_loss: 0.5386 - age_output_loss: 0.4421 - weight_output_loss: 0.4089 - bag_output_loss: 0.4874 - footwear_output_loss: 0.4817 - pose_output_loss: 0.3227 - emotion_output_loss: 0.3646 - gender_output_acc: 0.8465 - image_quality_output_acc: 0.7167 - age_output_acc: 0.8003 - weight_output_acc: 0.8188 - bag_output_acc: 0.7666 - footwear_output_acc: 0.7638 - pose_output_acc: 0.8590 - emotion_output_acc: 0.8564 - val_loss: 0.3427 - val_gender_output_loss: 0.3475 - val_image_quality_output_loss: 0.5485 - val_age_output_loss: 0.4419 - val_weight_output_loss: 0.4115 - val_bag_output_loss: 0.5055 - val_footwear_output_loss: 0.4803 - val_pose_output_loss: 0.3126 - val_emotion_output_loss: 0.3788 - val_gender_output_acc: 0.8681 - val_image_quality_output_acc: 0.7083 - val_age_output_acc: 0.8018 - val_weight_output_acc: 0.8196 - val_bag_output_acc: 0.7551 - val_footwear_output_acc: 0.7652 - val_pose_output_acc: 0.8666 - val_emotion_output_acc: 0.8493\n",
            "Epoch 60/200\n",
            "Epoch 60/200\n",
            "360/360 [==============================] - 149s 414ms/step - loss: 0.3389 - gender_output_loss: 0.3474 - image_quality_output_loss: 0.5366 - age_output_loss: 0.4426 - weight_output_loss: 0.4079 - bag_output_loss: 0.4823 - footwear_output_loss: 0.4792 - pose_output_loss: 0.3283 - emotion_output_loss: 0.3646 - gender_output_acc: 0.8442 - image_quality_output_acc: 0.7182 - age_output_acc: 0.7995 - weight_output_acc: 0.8204 - bag_output_acc: 0.7703 - footwear_output_acc: 0.7670 - pose_output_acc: 0.8571 - emotion_output_acc: 0.8565 - val_loss: 0.3461 - val_gender_output_loss: 0.3831 - val_image_quality_output_loss: 0.5508 - val_age_output_loss: 0.4440 - val_weight_output_loss: 0.4105 - val_bag_output_loss: 0.5060 - val_footwear_output_loss: 0.4700 - val_pose_output_loss: 0.3178 - val_emotion_output_loss: 0.3784 - val_gender_output_acc: 0.8413 - val_image_quality_output_acc: 0.7136 - val_age_output_acc: 0.8010 - val_weight_output_acc: 0.8211 - val_bag_output_acc: 0.7472 - val_footwear_output_acc: 0.7712 - val_pose_output_acc: 0.8700 - val_emotion_output_acc: 0.8511\n",
            "360/360 [==============================] - 149s 414ms/step - loss: 0.3389 - gender_output_loss: 0.3474 - image_quality_output_loss: 0.5366 - age_output_loss: 0.4426 - weight_output_loss: 0.4079 - bag_output_loss: 0.4823 - footwear_output_loss: 0.4792 - pose_output_loss: 0.3283 - emotion_output_loss: 0.3646 - gender_output_acc: 0.8442 - image_quality_output_acc: 0.7182 - age_output_acc: 0.7995 - weight_output_acc: 0.8204 - bag_output_acc: 0.7703 - footwear_output_acc: 0.7670 - pose_output_acc: 0.8571 - emotion_output_acc: 0.8565 - val_loss: 0.3461 - val_gender_output_loss: 0.3831 - val_image_quality_output_loss: 0.5508 - val_age_output_loss: 0.4440 - val_weight_output_loss: 0.4105 - val_bag_output_loss: 0.5060 - val_footwear_output_loss: 0.4700 - val_pose_output_loss: 0.3178 - val_emotion_output_loss: 0.3784 - val_gender_output_acc: 0.8413 - val_image_quality_output_acc: 0.7136 - val_age_output_acc: 0.8010 - val_weight_output_acc: 0.8211 - val_bag_output_acc: 0.7472 - val_footwear_output_acc: 0.7712 - val_pose_output_acc: 0.8700 - val_emotion_output_acc: 0.8511\n",
            "Epoch 61/200\n",
            "Epoch 61/200\n",
            "360/360 [==============================] - 149s 413ms/step - loss: 0.3376 - gender_output_loss: 0.3389 - image_quality_output_loss: 0.5373 - age_output_loss: 0.4421 - weight_output_loss: 0.4078 - bag_output_loss: 0.4834 - footwear_output_loss: 0.4827 - pose_output_loss: 0.3200 - emotion_output_loss: 0.3637 - gender_output_acc: 0.8537 - image_quality_output_acc: 0.7196 - age_output_acc: 0.8006 - weight_output_acc: 0.8199 - bag_output_acc: 0.7677 - footwear_output_acc: 0.7657 - pose_output_acc: 0.8630 - emotion_output_acc: 0.8570 - val_loss: 0.3484 - val_gender_output_loss: 0.3508 - val_image_quality_output_loss: 0.5420 - val_age_output_loss: 0.4491 - val_weight_output_loss: 0.4216 - val_bag_output_loss: 0.5039 - val_footwear_output_loss: 0.4745 - val_pose_output_loss: 0.3520 - val_emotion_output_loss: 0.3901 - val_gender_output_acc: 0.8514 - val_image_quality_output_acc: 0.7159 - val_age_output_acc: 0.8014 - val_weight_output_acc: 0.8120 - val_bag_output_acc: 0.7579 - val_footwear_output_acc: 0.7688 - val_pose_output_acc: 0.8542 - val_emotion_output_acc: 0.8511\n",
            "360/360 [==============================] - 149s 413ms/step - loss: 0.3376 - gender_output_loss: 0.3389 - image_quality_output_loss: 0.5373 - age_output_loss: 0.4421 - weight_output_loss: 0.4078 - bag_output_loss: 0.4834 - footwear_output_loss: 0.4827 - pose_output_loss: 0.3200 - emotion_output_loss: 0.3637 - gender_output_acc: 0.8537 - image_quality_output_acc: 0.7196 - age_output_acc: 0.8006 - weight_output_acc: 0.8199 - bag_output_acc: 0.7677 - footwear_output_acc: 0.7657 - pose_output_acc: 0.8630 - emotion_output_acc: 0.8570 - val_loss: 0.3484 - val_gender_output_loss: 0.3508 - val_image_quality_output_loss: 0.5420 - val_age_output_loss: 0.4491 - val_weight_output_loss: 0.4216 - val_bag_output_loss: 0.5039 - val_footwear_output_loss: 0.4745 - val_pose_output_loss: 0.3520 - val_emotion_output_loss: 0.3901 - val_gender_output_acc: 0.8514 - val_image_quality_output_acc: 0.7159 - val_age_output_acc: 0.8014 - val_weight_output_acc: 0.8120 - val_bag_output_acc: 0.7579 - val_footwear_output_acc: 0.7688 - val_pose_output_acc: 0.8542 - val_emotion_output_acc: 0.8511\n",
            "Epoch 62/200\n",
            "Epoch 62/200\n",
            "360/360 [==============================] - 148s 411ms/step - loss: 0.3368 - gender_output_loss: 0.3395 - image_quality_output_loss: 0.5331 - age_output_loss: 0.4414 - weight_output_loss: 0.4087 - bag_output_loss: 0.4800 - footwear_output_loss: 0.4801 - pose_output_loss: 0.3225 - emotion_output_loss: 0.3629 - gender_output_acc: 0.8511 - image_quality_output_acc: 0.7205 - age_output_acc: 0.8002 - weight_output_acc: 0.8198 - bag_output_acc: 0.7724 - footwear_output_acc: 0.7665 - pose_output_acc: 0.8624 - emotion_output_acc: 0.8566 - val_loss: 0.3559 - val_gender_output_loss: 0.4475 - val_image_quality_output_loss: 0.5556 - val_age_output_loss: 0.4426 - val_weight_output_loss: 0.4098 - val_bag_output_loss: 0.5051 - val_footwear_output_loss: 0.4810 - val_pose_output_loss: 0.3371 - val_emotion_output_loss: 0.3807 - val_gender_output_acc: 0.8100 - val_image_quality_output_acc: 0.6986 - val_age_output_acc: 0.7999 - val_weight_output_acc: 0.8240 - val_bag_output_acc: 0.7568 - val_footwear_output_acc: 0.7632 - val_pose_output_acc: 0.8624 - val_emotion_output_acc: 0.8508\n",
            "360/360 [==============================] - 148s 411ms/step - loss: 0.3368 - gender_output_loss: 0.3395 - image_quality_output_loss: 0.5331 - age_output_loss: 0.4414 - weight_output_loss: 0.4087 - bag_output_loss: 0.4800 - footwear_output_loss: 0.4801 - pose_output_loss: 0.3225 - emotion_output_loss: 0.3629 - gender_output_acc: 0.8511 - image_quality_output_acc: 0.7205 - age_output_acc: 0.8002 - weight_output_acc: 0.8198 - bag_output_acc: 0.7724 - footwear_output_acc: 0.7665 - pose_output_acc: 0.8624 - emotion_output_acc: 0.8566 - val_loss: 0.3559 - val_gender_output_loss: 0.4475 - val_image_quality_output_loss: 0.5556 - val_age_output_loss: 0.4426 - val_weight_output_loss: 0.4098 - val_bag_output_loss: 0.5051 - val_footwear_output_loss: 0.4810 - val_pose_output_loss: 0.3371 - val_emotion_output_loss: 0.3807 - val_gender_output_acc: 0.8100 - val_image_quality_output_acc: 0.6986 - val_age_output_acc: 0.7999 - val_weight_output_acc: 0.8240 - val_bag_output_acc: 0.7568 - val_footwear_output_acc: 0.7632 - val_pose_output_acc: 0.8624 - val_emotion_output_acc: 0.8508\n",
            "Epoch 63/200\n",
            "Epoch 63/200\n",
            "360/360 [==============================] - 148s 412ms/step - loss: 0.3352 - gender_output_loss: 0.3298 - image_quality_output_loss: 0.5354 - age_output_loss: 0.4418 - weight_output_loss: 0.4069 - bag_output_loss: 0.4817 - footwear_output_loss: 0.4804 - pose_output_loss: 0.3123 - emotion_output_loss: 0.3639 - gender_output_acc: 0.8563 - image_quality_output_acc: 0.7204 - age_output_acc: 0.8009 - weight_output_acc: 0.8205 - bag_output_acc: 0.7709 - footwear_output_acc: 0.7669 - pose_output_acc: 0.8655 - emotion_output_acc: 0.8559 - val_loss: 0.3588 - val_gender_output_loss: 0.3659 - val_image_quality_output_loss: 0.5489 - val_age_output_loss: 0.4556 - val_weight_output_loss: 0.4228 - val_bag_output_loss: 0.5105 - val_footwear_output_loss: 0.4888 - val_pose_output_loss: 0.3944 - val_emotion_output_loss: 0.4010 - val_gender_output_acc: 0.8433 - val_image_quality_output_acc: 0.7078 - val_age_output_acc: 0.8021 - val_weight_output_acc: 0.8191 - val_bag_output_acc: 0.7545 - val_footwear_output_acc: 0.7609 - val_pose_output_acc: 0.8492 - val_emotion_output_acc: 0.8497\n",
            "360/360 [==============================] - 148s 412ms/step - loss: 0.3352 - gender_output_loss: 0.3298 - image_quality_output_loss: 0.5354 - age_output_loss: 0.4418 - weight_output_loss: 0.4069 - bag_output_loss: 0.4817 - footwear_output_loss: 0.4804 - pose_output_loss: 0.3123 - emotion_output_loss: 0.3639 - gender_output_acc: 0.8563 - image_quality_output_acc: 0.7204 - age_output_acc: 0.8009 - weight_output_acc: 0.8205 - bag_output_acc: 0.7709 - footwear_output_acc: 0.7669 - pose_output_acc: 0.8655 - emotion_output_acc: 0.8559 - val_loss: 0.3588 - val_gender_output_loss: 0.3659 - val_image_quality_output_loss: 0.5489 - val_age_output_loss: 0.4556 - val_weight_output_loss: 0.4228 - val_bag_output_loss: 0.5105 - val_footwear_output_loss: 0.4888 - val_pose_output_loss: 0.3944 - val_emotion_output_loss: 0.4010 - val_gender_output_acc: 0.8433 - val_image_quality_output_acc: 0.7078 - val_age_output_acc: 0.8021 - val_weight_output_acc: 0.8191 - val_bag_output_acc: 0.7545 - val_footwear_output_acc: 0.7609 - val_pose_output_acc: 0.8492 - val_emotion_output_acc: 0.8497\n",
            "Epoch 64/200\n",
            "Epoch 64/200\n",
            "266/360 [=====================>........] - ETA: 37s - loss: 0.3344 - gender_output_loss: 0.3361 - image_quality_output_loss: 0.5330 - age_output_loss: 0.4431 - weight_output_loss: 0.4084 - bag_output_loss: 0.4764 - footwear_output_loss: 0.4735 - pose_output_loss: 0.3131 - emotion_output_loss: 0.3608 - gender_output_acc: 0.8508 - image_quality_output_acc: 0.7222 - age_output_acc: 0.8005 - weight_output_acc: 0.8193 - bag_output_acc: 0.7768 - footwear_output_acc: 0.7701 - pose_output_acc: 0.8643 - emotion_output_acc: 0.8582Buffered data was truncated after reaching the output size limit.Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}